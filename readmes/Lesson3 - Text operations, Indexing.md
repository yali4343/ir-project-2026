<link rel="stylesheet" href="./pdf_rtl_styles.css">

<style>
body, div, p, li, ul, ol { direction: rtl; text-align: right; }
</style>

# **סיכום שיעור 3 — אחזור מידע (Information Retrieval, IR)**

<div dir="rtl">


---

## שיטות גזירה (Stemming Methods)

- חיפוש בטבלה (Table Lookup)

- N-gram

- הסרת תחיליות/סיומות (Affix Removal: suffix, prefix)

- הסרה פשוטה – פורטר (Porter)

- התאמה הארוכה ביותר – לובינס (Lovins, לא מכוסה)

---

## שיטות גזירה (#1): חיפוש בטבלה

- שימוש בטבלה מוגדרת מראש לגזירה (מיפוי כל צורה לשורש בסיסי)

| מונח | שורש |
|------|------|
| Teaching | teach |
| Teaches  | teach |
| Taught   | teach |
| Teacher  | teach |

---

## גזירה בטבלה – יתרונות וחסרונות

חסרונות:

- לא קיימת טבלת גזירה שלמה לאנגלית.

- תקורה באחסון (Storage Overhead) – דורש לשמור את כל המיפויים.

יתרונות:

- קל ליישום; זמן חיפוש יעיל (גישה ישירה לשורש).

- מתאים במיוחד לאוספים סטטיים או מוגבלים בגודל.

---

## שיטות גזירה (#2): גוזרי N-gram

- פירוק כל מונח לרצפים בני n תווים עוקבים (למשל n=2 זוגות אותיות / דיגרמות).

- חישוב מדדי קשר (Association Measures) בין זוגות מונחים על סמך דיגרמות ייחודיות משותפות.

- אלגוריתם: עבור כל מונח חדש – בדוק אם הוא שורש של מונח קיים (מספיק חפיפה בדיגרמות); אחרת הוסף לאינדקס כשורש חדש.

- שימושי בשפות עם נטייה מורפולוגית מורכבת או ללא כללים סדורים ברורים.

---

## גוזרי N-gram – דוגמה

- דוגמה להשוואה בין שני מונחים:

- statistics → st ta at ti is st ti ic cs

- דיגרמות ייחודיות: ta, at, cs, ic, is, st, ti

- statistical → st ta at ti is st ti ic ca al

- דיגרמות ייחודיות: al, at, ca, ic, is, st, ta, ti

- מספר דיגרמות משותפות (חפיפה): 6

- רעיון: ככל שמספר הדיגרמות הייחודיות המשותפות גבוה יותר כך סביר שמדובר בווריאציה של אותו שורש.

---

## מדדי דמיון – מקדם Dice

![alt text]({EE22512B-E6DA-4C41-80FF-DBE3AAA8EAEB}.png)

---

## מדד דמיון אפשרות 2 – מקדם Jaccard

- מדד שימושי לכיסוי החפיפה בין שתי קבוצות.

- בהינתן שתי קבוצות \(X\) ו-\(Y\): 

![alt text]({47B2B0D9-DF3F-4F20-B1B1-DB9C4BBF80EF}.png)

- ערך 1 כאשר כל האיברים זהים; ערך 0 כאשר אין איברים משותפים.

- הקבוצות אינן חייבות להיות באותו גודל.

- דוגמה: \(6/9 = 0.66\) (9 = סך כל הדיגרמות הייחודיות המאוחדות).

- תמיד תחום בין 0 ל-1; ניתן לקבוע סף (למשל J > 0.8) כדי להכריז על התאמה.

- יתרון: פשוט להבנה ולחישוב; חסרון: מתעלם ממשקל שכיחויות (סופרת נוכחות בלבד).

---

## שיטות גזירה (#3): הסרת תחיליות/סיומות (Affix Removal)

- אלגוריתמים שמסירים תחיליות ו/או סיומות ומשאירים שורש בסיסי.

- דוגמה לכלל: אם מילה מסתיימת ב"ies" (אבל לא ב-eies או aies) <- החלף ל-"y" (studies → study).

- דוגמה נוספת: אם מסתיימת ב"es" אך לא ב"aes", "ees" או "oes" <- הסר ה-s (tables → table; referees לא <- referee כי התנאים שונים).

- מטרה: הפחתת וריאציות צורניות כדי לאחד אינדוקס וחיפוש.

- סיכון: הסרה אגרסיבית עלולה ליצור שורשים לא קיימים (over-stemming).

---

## גוזרי הסרת תחיליות – התאמה הארוכה לעומת כלל פשוט

- התאמה ארוכה (Longest Match) מסירה את רצף התווים הארוך ביותר האפשרי מתוך רשימת סיומות מוכרת – מקטין וריאציות, אך דורש רשימה רחבה.

- כלל פשוט משתמש ברשימת סיומות קצרה ובבדיקות תנאי בסיסיות – קל יותר לתחזוקה אך פחות מדויק.

- אלגוריתם פורטר: משתמש ברשימת סיומות בשלבים, מסיר בהדרגה ומונע הסרה מיותרת.

---

## אלגוריתם פורטר (Porter’s Algorithm)

- אחד האלגוריתמים הנפוצים ביותר לגזירת מילים באנגלית.

- מחקרים מצביעים שהוא לפחות טוב כמו חלופות נפוצות אחרות.

- מבנה: מוסכמות + 5 שלבים של הפחתה (Reduction Phases).

- כל שלב מורכב מקבוצת פקודות (חוקים) הנבדקות ברצף.

- מוסכמה לדוגמה: "אם מספר חוקים רלוונטיים – בחר את זה שמתאים לסיומת הארוכה ביותר".

- יתרון: איזון טוב בין שמירת משמעות לבין קיצור צורות.

---

## חוקים טיפוסיים באלגוריתם פורטר

- sses → ss

- ies → i

- ational → ate

- tional → tion

- משקל רגישות למבנה המילה (Word Sensitive Rules):

- (m>1) EMENT →

- replacement → replac

- cement → cement (לא משתנה כי התנאי m>1 אינו מתקיים או לא רלוונטי בהתאם להקשר המדויק).

- הערה: סימון m מודד עומק רצפים תנועתיים/עיצוריים ומונע קיצור יתר.

---

## אלגוריתם הגזירה של פורטר – עקרונות פנימיים

- מבוסס על מדידה של רצפי תנועה–עיצור (VC): \( m = [C](VC)^n[V] \) כאשר C רצף עיצורים ו-V רצף תנועות (כולל "y"). סימון [] מציין אופציונליות.

- דוגמאות ערכי m: m=0 (tree, by), m=1 (trouble, oats, trees, ivy), m=2 (troubles, private).

- סימון חלקי:

- *<X> <- שורש מסתיים באות X.

- *v* <- השורש מכיל תנועה.

- *d <- מסתיים בעיצור כפול.

- *o <- מסתיים ברצף cvc שעיצורים הסופי אינו w, x, y.

- האלגוריתם בנוי מחוקי תנאי–פעולה: "סיומת ישנה → סיומת חדשה" בשלבים; בכל שלב נבדקים החוקים לפי סדר מוגדר.

- יעילות ממוצעת טובה: איזון בין Recall (כיסוי וריאציות) ו-Precision (אי פגיעה במשמעות).

- סיכום: עיצוב רב-שלבי מפחית טעויות של גזירה אגרסיבית ושומר על יציבות באינדקס.

---

## מבחר חוקים מאלגוריתם פורטר (טבלה)

| שלב | תנאי | סיומת | החלפה | דוגמה |
|:---:|:---:|:---:|:---:|:---:|
| 1a | NULL | sses | ss | stresses → stress |
| 1a | NULL | ies | i | ponies → poni |
| 1a | NULL | ss | ss | caress → caress |
| 1a | NULL | s | NULL | cats → cat |
| 1b | *v* | ing | NULL | making → mak |
| 1b1 | NULL | at | ate | inflate → inflate |
| 1c | *v* | y | i | happy → happi |
| 2 | m > 0 | aliti | al | formality → formal |
| 2 | m > 0 | izer | ize | digitizer → digitize |
| 3 | m > 0 | icate | ic | duplicate → duplic |
| 4 | m > 1 | able | NULL | adjustable → adjust |
| 4 | m > 1 | icate | NULL | microscopic → microscop |
| 5a | m > 1 | e | NULL | inflate → inflat |
| 5b | m > 1, *d, *<L> | NULL | single letter | controll → control, roll → roll |


---

## בעיות בשיטות גזירה (Stemming Methods: Problems)

- גזירת־יתר (Overstemming) – לדוגמה: redim → red.

- גזירה־חסרה (Understemming) – לדוגמה: users → user.

- שגיאות "הכללה" (Comission):

- organization, organ → organ.

- Executive, execute → execut.

- arm, army → arm.

- University, universe → univers.

- שגיאות "השמטה" (Omission):

- cylinder, cylindrical.

- create, creation.

- Europe, European.

- דיוק (Accuracy): לדוגמה skies → sky ולא ski — דרוש כלל מיוחד עבור האות k ברבים.

- כיצד מעריכים Stemmers? אילו מדדים להשתמש?
  - תשובה: בדרך כלל מעריכים לפי השיפור בביצועי האחזור (Recall/Precision) על אוסף מבחן סטנדרטי, או באמצעות בדיקת נכונות לשונית (פחות נפוץ בהקשר של IR).

---

## 1. בנייה פשוטה של אינדקס (Simple Index Construction)

אינדקס הפוך (Inverted Index)

- בנייה ושליפה (Construction & Retrieval)

- מבני נתונים שימושיים (Useful Data Structures)

- דחיסה (Compression)

החלטות אינדוקס (Indexing Decisions):

- אוצר מילים (Vocabulary)

- חוק היפס (Heaps’ law)

- שאילתות ביטוי (Phrase Queries)

---

## אינדקסים (Indexes)

- אינדקסים הם מבני נתונים שנועדו להאיץ חיפוש.

- לחיפוש טקסט דרישות ייחודיות שמובילות למבני נתונים ייחודיים.

מבנה הנתונים הנפוץ ביותר הוא אינדקס הפוך (inverted index).

- שם כללי למשפחת מבנים.

- "הפוך" כי המסמכים משויכים למילים, ולא המילים למסמכים.

---

## Inverted Index — ייצוג האינדקס

![alt text]({4BA1DF70-46BF-4898-B766-CB5983DAD7F5}.png)

השקף מציג דוגמה לבניית אינדקס הפוך (Inverted Index) מתוך אוסף מסמכים קטן.

**הקלט (Documents):**

ישנם 3 מסמכים (משפטים):

1. Winter is coming.
2. Ours is the fury.
3. The choice is yours.

**תהליך הבנייה:**

1. **Tokenization & Normalization**: פירוק למילים והמרה לאותיות קטנות (למשל Winter הופך ל-winter).
2. **Dictionary (מילון)**: רשימת המונחים הייחודיים ממוינת לפי סדר אלפביתי (choice, coming, fury...).
3. **Frequency (שכיחות)**: מספר המסמכים בהם המונח מופיע (Document Frequency). למשל, המילה "is" מופיעה ב-3 מסמכים.
4. **Postings (רשימות מסמכים)**: לכל מונח מוצמדת רשימה של מזהי המסמכים (DocIDs) בהם הוא מופיע.
   - המילה "winter" מופיעה רק במסמך 1.
   - המילה "the" מופיעה במסמכים 2 ו-3.

מבנה זה מאפשר חיפוש מהיר: במקום לעבור על כל המסמכים, ניגשים ישירות למונח במילון ומקבלים את רשימת המסמכים הרלוונטיים.

---

## Inverted Index — בנייה פשוטה בזיכרון

  עבור כל מסמך:

- בצע Tokenize למסמך.

- רשום אילו טוקנים הופיעו במסמך זה.

  - עדכן את המילון (במידת הצורך) עם מצביע חדש לקובץ ה-postings.

  - צור/עדכן את קובץ ה-postings — ניתן לשמור מידע נוסף (מיקום, גופן, טיפוס, tf-idf וכו').

---

## Inverted Index — אלגוריתם שליפה

1. חיפוש באוצר המילים.

2. קביעת קבוצת המסמכים המועמדים לתשובה.

3. חלת פונקציית השליפה על המסמכים המתאימים.

---

## עיבוד שאילתות AND

נניח שאילתה: Brutus AND Caesar.

- אתר את Brutus במילון וקבל את רשימת המסמכים שלו (postings).

- אתר את Caesar במילון וקבל את רשימת המסמכים שלו (postings).

- בצע מיזוג בעזרת חיתוך בין שתי הרשימות כדי לקבל את קבוצת המסמכים המשותפת.

![alt text]({22CD108B-BB83-4E16-81BD-53FC80110987}.png)

- חיוני שה-postings יהיו ממוינות כדי לאפשר מיזוג ליניארי ויעיל.

---

## דירוג באמצעות דמיון קוסינוס (Cosine Similarity)


- דמיון קוסינוס מודד את הקוסינוס של הזווית בין וקטור השאילתה לבין וקטור כל מסמך.

![alt text]({42D3DEA9-76D9-4E7E-BE8E-09CB342925D6}.png)

- הערך בתחום 0–1; נורמליזציה לפי אורך הווקטורים מונעת הטיית מסמכים ארוכים.

- כל ציר מייצג מונח; הזווית קטנה יותר -> דמיון גבוה יותר.

---

## שליפה נאיבית (Naïve Retrieval)

![alt text]({13A35C3C-6A6C-43EC-92F5-2339D04F555E}.png)

- אתחל לכל מסמך d_i: sim(q, d_i) = 0.

- עבור כל מסמך d_i ולכל מונח t_j:

- אם t_j מופיע גם בשאילתה וגם ב-d_i, הוסף: sim(q, d_i) += q_j · w_{ij}.

- נרמל: sim(q, d_i) = sim(q, d_i) · NF[i] · (1/|q|).

- מיין את המסמכים לפי הדמיון בסדר יורד והצג את ה-top k למשתמש.

---

## קבצים הפוכים (Inverted Files)

![alt text]({AC9C5BDE-EF73-495C-BACC-AD1FD3A34B0D}.png)


---

## שליפה בעזרת אינדקס הפוך (Retrieval using Inverted Index)

![alt text]({48F1D47E-F854-4B0B-A20D-B64DEDB519A4}.png)

![alt text]({4C82D6C6-43E5-49E7-AEFA-964477FB63D4}.png)
---

## שליפה יעילה – דוגמה (Efficient Retrieval: Example)



הדוגמה מראה כיצד מחשבים את דמיון הקוסינוס (Cosine Similarity) בין שאילתה למסמכים באמצעות אינדקס הפוך, צעד אחר צעד.

![alt text]({4612B1A7-E315-4A78-A1F0-C8A3F44E53AD}.png)

---

## מבני נתונים שימושיים (Useful Data Structures)

- מילון / סטטיסטיקות גלובליות:

  - Hashtable

  - עצים (Binary, B-Tree)

- רשימות Postings:

  - מערכים ממוינים. מדוע לא רשימות רגילות?
    - תשובה: רשימות מקושרות דורשות יותר זיכרון (מצביעים), אינן תומכות בגישה אקראית יעילה, ופחות ידידותיות למטמון (cache) בהשוואה למערכים רציפים.

---

## מבני נתונים לרשימות Postings (Data Structures for Posting Lists)

- מערכים ממוינים –

  - זולים במקום אחסון.

  - ביצועים תחרותיים O(log n) כאשר משתמשים בחיפוש בינארי.

  - יקרים בעדכון.

  - קלים ליישום.

  - בשימוש רחב מאוד.

---

## מבני נתונים למילון (Dictionary Data Structures)

- שתי אפשרויות נוספות:

  - Hashtables

  - Trees

- מערכות IR שונות משתמשות לעיתים בטבלאות גיבוב ולעיתים בעצים.

---

## טבלאות גיבוב (Hashtables)

- כל מונח באוצר המילים ממופה למספר שלם ע"י פונקציית גיבוב.

  - (מניחים שכבר נתקלת בטבלאות גיבוב בעבר)

- יתרונות:

  - חיפוש מהיר יותר מאשר בעץ: O(1) אמורפי.

- חסרונות:

  - אין דרך קלה למצוא וריאציות קטנות (judgment / judgement).

  - אין חיפוש לפי תחילית (Prefix Search) – רלוונטי ל-[tolerant retrieval].

  - אם אוצר המילים גדל מתמשך, נדרש לעיתים לבצע Rehash לכל המילון (פעולה כבדה).

---

## עץ: עץ בינארי (Tree: Binary Tree)

![alt text]({F82D7145-17EE-4C05-8286-4DB0ED934921}.png)



---

## עץ: B-Tree

![alt text]({3AFCB660-C28D-418C-851E-04EAE14396A4}.png)

---

## עצים (Trees)

- הפשוט ביותר: עץ בינארי.

- הנפוץ יותר בפועל: עצי B.

- עצים דורשים סדר לקסיקוגרפי סטנדרטי של תווים ולכן גם של מחרוזות – בדרך־כלל יש לנו כזה.

- יתרונות:

  - פותרים את בעיית התחילית (חיפוש מונחים המתחילים ב‑hyp).

- חסרונות:

  - איטיים יותר: O(log M) [ודורש עץ מאוזן].

  - איזון עצים בינאריים הוא יקר.

  - עצי B מקלים על בעיית האיזון.

---

## דחיסת אינדקס (Index Compression)

- המילון → RAM.

- רשימות ה‑postings → דיסק.

- קבצי postings מהווים בערך 30%–40% מגודל הטקסט עם דחיסה סבירה.

- טכניקות דחיסה שימושיות:

  - קידוד הבדלי מרחקים בין מזהים (gap/interval difference).

  - מספרים נפוצים מקודדים באמצעות פחות ביטים.

  - אינו פוגע משמעותית בביצועים.

- פרק 5 בספר – ללמידה עצמית.

---

## החלטות אינדוקס – סוגי מונחים לכלול (Indexing decisions)

- מגבלות על רשימת עצירה, רווחים, פיסוק, ספרות, תחיליות סטנדרטיות וכו'.

- מילים בודדות או צירופים (phrases).

- מילים נרדפות, מילים קשורות סמנטית, וריאציות מורפולוגיות, אוצר מילים ידוע.

---

## החלטות אינדוקס – איזה מידע לשמור

- מצביע למסמך.

- מיקום המונח (בקובץ ה‑postings).

- תדירות במסמך ובאוסף (באינדקס/ב‑postings).

- במנועי חיפוש – נשמר מידע מפורט מאוד על כל הופעה של מונח בעמוד.

---

## החלטות אינדוקס – כיסוי מול ספציפיות

- פשרה בין כיסוי לספציפיות.

- האוצר מילים הוא המפתח!

  - כיצד הוא גדל ככל שמוסיפים מסמכים?
    - תשובה: לפי חוק היפס, הוא גדל בצורה תת-ליניארית ($V = K n^{\beta}$), כלומר ממשיך לגדול אך הקצב יורד.

  - אינו חסום מלמעלה.

  - ניתן להשתמש ב‑stemming ובגיזום מילים לא‑מהותיות כדי לצמצם את הגודל.

---

## חוק היפס (Heaps’ Law)

![alt text]({68FBDF26-5CDA-46B5-A9F3-FED751B9C934}.png)

---

## נתוני חוק היפס (Heaps’ Law Data)

![alt text](image.png)

הגרף מציג נתונים אמיתיים מאוספי טקסט שונים (כגון כתבות חדשותיות מ-AP, Wall Street Journal וכו') המדגימים את חוק היפס.

- **ציר ה-X**: גודל האוסף ($N$) במיליוני מילים (Tokens).
- **ציר ה-Y**: גודל אוצר המילים ($V$) באלפי מילים (Types).

מה ניתן ללמוד מהגרף?

1. **גידול תת-ליניארי**: העקומות אינן קווים ישרים אלא קעורות, מה שמאשר שהחזקה $\beta$ קטנה מ-1 (לרוב סביב 0.5). ככל שהאוסף גדל, קצב גילוי המילים החדשות יורד.
2. **אין התכנסות**: העקומות ממשיכות לעלות גם עבור אוספים גדולים מאוד. זה אומר שאוצר המילים אינו סופי בפרקטיקה; תמיד נתקלים במילים חדשות (שמות פרטיים, שגיאות כתיב, מונחים חדשים).
3. **הבדלים בין אוספים**: לכל אוסף יש פרמטרים ($K, \beta$) מעט שונים, התלויים באופי הטקסט (עושר לשוני, נושאים וכו'), אך הצורה הכללית נשמרת.

---

## שאילתות ביטוי (Phrase queries)

- למשל: "Ben‑Gurion University".

- למה זה חשוב?
  - תשובה: משתמשים רבים מחפשים שמות ספציפיים, כותרות או מושגים המורכבים ממספר מילים, והסדר ביניהן קריטי למשמעות.

- כיצד תומכים בזה?
  - תשובה: באמצעות אינדקסים מיוחדים כמו אינדקס דו-מילים (Biword Index) או אינדקס מיקומים (Positional Index).

---

## ניסיון ראשון: אינדקס דו-מילים (Biword Indexes)

- אינדוקס כל זוג רציף של מונחים בטקסט כביטוי (biword).

  - friends romans

  - romans countrymen

- למשל הטקסט "Friends, Romans, Countrymen" יפיק את זוגות־המילים לעיל.

- כל אחד מזוגות אלה הופך לערך מילון.

- עיבוד שאילתת ביטוי של שתי מילים הופך למיידי.

---

## בעיות באינדקסי דו-מילים (Issues for Biword Indexes)

- התפוצצות גודל האינדקס בגלל מילון גדול יותר.

  - לא מעשי ליותר מזוגות-מילים; גדול אפילו עבורם.

- אבל יכול להיות רכיב בתוך אסטרטגיה מרוכבת (Compound Strategy).

---

## שאילתות ביטוי – פתרון #2 (Phrase Queries – Solution #2)

- למשל: "Ben-Gurion University".

- מדוע זה חשוב?
  - תשובה: כפי שהוזכר, לדיוק בחיפוש ביטויים מדויקים.

- איך תומכים בזה?
  - תשובה: באמצעות אינדקס מיקומים (Positional Index) ששומר את המיקום של כל מילה במסמך.

- אינדקס מיקומים (Positional Index):

  - <מונח, #מסמכים המכילים את המונח;>

  - doc1: [מיקום1, מיקום2 ...];

  - doc2: [מיקום1, מיקום2 ...]; וכו'.

---

## השפעות אינדקס מיקומים (Impacts of Positional Index)

- אינדקס מיקומים מגדיל משמעותית את נפח אחסון ה‑postings.

  - בערך פי 2–4 בגודל באנגלית.

- עלות זמן ריצה. למה?
  - תשובה: עיבוד השאילתה דורש בדיקת תנאי סמיכות (proximity) ומעבר על כמות גדולה יותר של נתונים (מיקומים) בהשוואה לחיתוך בוליאני פשוט.

- אבל:

  - דחיסה טובה מצמצמת זאת במידה מסוימת.

  - שימושי לשאילתות ביטוי וגם לשאילתות קרבה (proximity) החשובות מאוד.

  - לכן אינדקסי מיקומים הם כיום הסטנדרט.

---

## יסודות חומרה (Hardware Basics)

- גישה לנתונים בזיכרון מהירה משמעותית לעומת גישה לנתונים בדיסק.

- פעולת Seek בדיסק: אין העברת נתונים בזמן שהראש ממוקם.

- לכן: העברת מקטע גדול אחד מהדיסק לזיכרון מהירה יותר מהעברת הרבה מקטעים קטנים.

- I/O בדיסק מבוסס בלוקים: קריאה וכתיבה של בלוקים שלמים (ולא חתיכות קטנות).

- גדלי בלוקים טיפוסיים: ‎8KB עד ‎256KB.

---

## הנחות חומרה להרצאה זו (Hardware Assumptions)

![alt text]({5B835153-5809-4BEE-8EB5-2CB006463F92}-1.png)

- זמן Seek ממוצע: \(5\times10^{-3}\) שניות = ‎5ms.

- זמן העברה לבייט: \(2\times10^{-8}\) שניות = ‎0.02µs.

- קצב שעון מעבד: \(10^{9}\) פעולות בשנייה.

  - פעולה ברמה נמוכה (השוואה + החלפת מילה) ~ \(10^{-8}\) שניות = ‎0.01µs.

- גודל הזיכרון הראשי: כמה GB.

- גודל שטח הדיסק: ~‎1TB או יותר.

---

## צוואר בקבוק בבנייה (Bottleneck)

- מבנים: פריסת מסמך (Parsing) ובניית רשומות postings אחד־אחד.

- לאחר מכן: למיין רשומות postings לפי מונח ולאחר מכן לפי מזהה מסמך בתוך כל מונח.

- ביצוע הפעולות עם דיסק Seeks אקראיים יהיה איטי מאוד – חייבים למיין \(T = 100\text{M}\) רשומות באופן יעיל.

- שאלה להערכת זמן: אם כל השוואה דורשת שני disk seeks וצריך \(N \log_2 N\) השוואות, כמה זמן נדרש? (הערכת סדרי גודל לזמן I/O).
  - תשובה: עבור $N=100M$ רשומות, נדרשות כ-$2.7 \times 10^9$ השוואות. עם 2 seeks להשוואה ו-5ms ל-seek, הזמן הכולל הוא כ-$2.7 \times 10^7$ שניות, שהן כ-312 ימים. זה איטי מדי באופן בלתי מעשי.

---

## מיון חיצוני (External Sorting)

- בעיה: למיין ‎100Gb נתונים עם ‎1Gb RAM.

- כאשר קובץ לא נכנס כולו לזיכרון יש שני שלבים:

1. חלוקת הקובץ למקטעים (runs) ומיון כל מקטע בנפרד.

2. מיזוג המקטעים הממוינים לרצף סופי ממוין.

- כל שלב כרוך בקריאה וכתיבה לפחות פעם אחת של כל הנתונים.

---

## מיון דו-כיווני דורש 3 חוצצים (2-Way Sort Requires 3 Buffers)

![alt text]({A433F892-32C8-4ECD-8A20-33AFCF545F5F}.png)

התרשים מתאר את תהליך המיזוג (Merge) של שני מקטעים ממוינים (Runs) המאוחסנים בדיסק, כאשר הזיכרון הראשי (RAM) מוגבל.

**התהליך:**

1. **קלט (Input Buffers):** מקצים שני חוצצים (Buffers) בזיכרון לקריאת נתונים. קוראים בלוק נתונים אחד מכל מקטע ממוין בדיסק אל תוך החוצצים (Input 1, Input 2).
2. **מיזוג (Merge):** המעבד משווה את האיברים הראשונים בכל חוצץ, בוחר את הקטן מביניהם (במיון עולה), ומעביר אותו לחוצץ הפלט (Output Buffer).
3. **פלט (Output Buffer):** כאשר חוצץ הפלט מתמלא, הוא נכתב חזרה לדיסק כחלק מהמקטע הממוין החדש והגדול יותר.
4. **רציפות:** כאשר אחד מחוצצי הקלט מתרוקן, קוראים את הבלוק הבא מהדיסק לאותו חוצץ, וכך ממשיכים עד שכל הנתונים מוזגו.

**דרישות זיכרון:**

כדי לבצע מיזוג דו-כיווני (2-Way Merge) יעיל, נדרשים לפחות **3 חוצצים** בזיכרון:

- 2 חוצצים לקלט (עבור שני המקטעים שמתמזגים).
- 1 חוצץ לפלט (לכתיבת התוצאה).

---

## מיון מיזוג דו-כיווני בזיכרון ראשי (Main Memory 2-Way Merge Sort)

![alt text]({EEE8B1D5-44DA-4BD2-AE69-0E2DC3E0CCF9}.png)

הדוגמה בתרשים ממחישה שלב אחד של מיזוג בין שני מקטעים (Runs):

**הנתונים:**

- **Input page 1**: מכיל את המספרים הממוינים {2, 3, 5, 6}.
- **Input page 2**: מכיל את המספרים הממוינים {1, 4, 8, 9}.
- **Output page**: צובר את התוצאה הממוינת.

**תהליך המיזוג:**

האלגוריתם משווה את האיברים הראשונים בכל חוצץ קלט ומעביר את הקטן ביותר לחוצץ הפלט:

1. השוואה בין 1 ל-2 -> **1** נבחר.
2. השוואה בין 2 ל-4 -> **2** נבחר.
3. השוואה בין 3 ל-4 -> **3** נבחר.
4. השוואה בין 5 ל-4 -> **4** נבחר.

כאשר חוצץ הפלט מתמלא ({1, 2, 3, 4}), הוא נכתב לדיסק, והתהליך ממשיך.

**ניתוח עלויות:**

- בכל מעבר (Pass) על הנתונים, אנו קוראים וכותבים את כל העמודים בקובץ פעם אחת.
- אם יש $N$ עמודים, מספר המעברים הנדרש הוא $\lceil \log_2 N \rceil + 1$.
- העלות הכוללת במונחי I/O היא: $2N \cdot (\lceil \log_2 N \rceil + 1)$.


---

## מיון מיזוג חיצוני דו-כיווני (Two-Way External Merge Sort)

![alt text]({0E2F9A02-A466-4FAF-ABA3-B1A161C35025}.png)

![alt text]({53234C9D-5B8D-436C-B156-D5AE12B7335B}.png)


---

## BSBI – אינדוקס חסום מבוסס מיון (Blocked Sort-Based Indexing)

- רשומות בגודל ‎12 בתים (4+4+4): (termid, docid, freq).

- נוצרות תוך כדי ניתוח המסמכים.

- צריך למיין עכשיו ‎100M רשומות כאלה לפי term.

- הגדרת Block: בערך ‎10M רשומות.

  - ניתן להכניס כמה בלוקים לזיכרון בו זמנית.

  - נניח התחלה עם ‎10 בלוקים.

- רעיון בסיסי של האלגוריתם:

  - לצבור postings לכל בלוק, למיין ולכתוב לדיסק.

  - למזג את כל הבלוקים לסדר ממוין ארוך אחד סופי.

![alt text]({1E1F0990-4A15-4EB5-8267-9AD2564AA729}.png)

**הסבר האלגוריתם:**

BSBI פותר את בעיית הזיכרון המוגבל על ידי פירוק המשימה:
1.  **חלוקה לבלוקים:** קוראים מסמכים ויוצרים זוגות (TermID, DocID) עד שהזיכרון מתמלא (בלוק).
2.  **מיון פנימי:** ממיינים את הבלוק הנוכחי בזיכרון לפי TermID.
3.  **שמירה זמנית:** כותבים את הבלוק הממוין לדיסק.
4.  **מיזוג סופי:** לאחר שכל המסמכים עובדו, ממזגים את כל הבלוקים הממוינים מהדיסק לאינדקס אחד שלם (בדומה למיון מיזוג חיצוני).

---

## מיון 10 בלוקים של 10M רשומות (Sorting 10 blocks of 10M records)

השקף מנתח את העלות של מיון בלוק בודד בזיכרון כחלק מאלגוריתם BSBI.

**התהליך:**
עבור כל אחד מ-10 הבלוקים (שכל אחד מכיל 10 מיליון רשומות):
1.  קוראים את הבלוק לזיכרון.
2.  ממיינים אותו פנימית (בזיכרון) באמצעות אלגוריתם מיון מהיר (Quicksort).

**ניתוח זמן ריצה (עבור בלוק אחד):**
-   אלגוריתם Quicksort מבצע בממוצע $2N \ln N$ השוואות.
-   במקרה שלנו, $N = 10,000,000$ (10 מיליון רשומות).
-   לכן מספר הצעדים הצפוי הוא: $2 \cdot 10^7 \cdot \ln(10^7)$.
-   חישוב זה מראה שמיון פנימי של בלוק בגודל כזה הוא מעשי ומהיר יחסית.

---

## BSBIIndexConstruction — תרשים אלגוריתם

![alt text]({C17D8BBD-8553-4EB3-84C3-7A78D950BDCD}.png)

![alt text]({C7F6833C-0409-4C3D-9468-6D94AAC7B9DA}.png)

---

## כיצד למזג את ה־runs הממוינים? (Binary merges)

![alt text]({E25D58A9-31A7-45D9-9D95-146C52E81A88}.png)

התרשים וההסבר עוסקים בשלב המיזוג של מקטעים (runs) ממוינים באלגוריתם BSBI:

**מה קורה בשלב זה?**
לאחר שמוינים כל הבלוקים בנפרד ונשמרים בדיסק, יש לאחד אותם לאינדקס אחד ממוין. הדרך הפשוטה היא לבצע מיזוגים בינאריים (כל פעם שני קבצים), בשכבות (layers):

1.  **עץ מיזוג בעומק $\log_2 10 = 4$:**
  - אם יש 10 בלוקים, נדרשות 4 שכבות של מיזוגים בינאריים עד שמתקבל קובץ ממוין יחיד.
2.  **בכל שכבה:**
  - קוראים ל-RAM שני קבצים בגודל 10 מיליון רשומות כל אחד.
  - ממזגים אותם לרצף ממוין חדש.
  - כותבים את התוצאה חזרה לדיסק.
3.  **יעילות:**
  - כל שכבת מיזוג דורשת קריאה וכתיבה של כל הנתונים.
  - ככל שיש יותר בלוקים, נדרשות יותר שכבות (לפי $\log_2$ של מספר הבלוקים).

**סיכום:**
המיזוג הבינארי מאפשר לאחד קבצים גדולים בזיכרון מוגבל, אך ככל שמספר הבלוקים הראשוניים גדול יותר, נדרשות יותר שכבות מיזוג, וכל שכבה מוסיפה עלות של קריאה וכתיבה מלאה של כל הנתונים.

- יעיל יותר לבצע מיזוג רב־כיווני שבו קוראים מכל הבלוקים בו־זמנית.

- אם קוראים מקטעים גדולים מספיק מכל בלוק לזיכרון ומוציאים מקטע פלט גדול מספיק — עלויות ה‑seek אינן כורעות את המערכת.

---

## בעיה שנותרה באלגוריתם מבוסס מיון

- ההנחה הייתה: ניתן להחזיק את המילון בזיכרון.

- אנו זקוקים למילון (שגדל דינמית) כדי לממש מיפוי מונח→termID.

- ניתן לעבוד ישירות עם postings של (term, docID) במקום (termID, docID),

  - אך אז קבצי הביניים נעשים גדולים מאוד — שיטה ניתנת להרחבה אך איטית מאוד לבניית אינדקס.

---

## SPIMI: אינדוקס חד־מעברי בזיכרון (Single‑pass In‑Memory Indexing)

- רעיון מפתח 1: ליצור מילונים נפרדים לכל בלוק – אין צורך לשמור מיפוי term↔termID בין בלוקים.

- רעיון מפתח 2: לא למיין – לצבור רשימות postings תוך כדי הופעה.

- עם שני הרעיונות אפשר לבנות אינדקס הפוך שלם לכל בלוק.

- לאחר מכן ניתן למזג את כל האינדקסים הנפרדים לאינדקס גדול אחד.

---

## SPIMI‑Invert — פסאודו‑קוד

![alt text]({4AFAFC0A-F1E5-4E5F-8C6B-B639E9D8E9C3}.png)

התרשים מציג את אלגוריתם SPIMI-Invert (Single-Pass In-Memory Indexing), שיטה יעילה לבניית אינדקס הפוך כאשר הזיכרון מוגבל:

**שלבי האלגוריתם:**
1. **אתחול:** פותחים קובץ פלט חדש ומילון (Hash) ריק בזיכרון.
2. **קריאת טוקנים:** כל עוד יש זיכרון פנוי, קוראים טוקן מהזרם.
3. **עדכון מילון:**
  - אם המונח לא קיים במילון, מוסיפים אותו ומקצים לו רשימת postings חדשה.
  - אם קיים, שולפים את רשימת ה-postings שלו.
4. **הרחבת רשימה:** אם הרשימה מלאה, מכפילים את גודלה.
5. **הוספה לרשימה:** מוסיפים את מזהה המסמך (docID) לרשימת ה-postings של המונח.
6. **סיום:** ממיינים את המונחים, כותבים את המילון וה-postings לדיסק, ומחזירים את קובץ הפלט.

**יתרונות SPIMI:**
- אין צורך למיין את כל הזוגות מראש — כל מונח נכנס למילון ברגע הופעתו.
- מתאים במיוחד לאוספים גדולים שלא נכנסים לזיכרון.
- כל בלוק נבנה בזיכרון ומאוחסן לדיסק; בסוף ממזגים את כל הבלוקים (בדומה ל-BSBI).

**הערה:** מיזוג הבלוקים דומה לאלגוריתם BSBI, אך SPIMI יעיל יותר כי הוא נמנע ממיונים מיותרים ומנצל טוב יותר את הזיכרון.

- הערה: מיזוג הבלוקים דומה לאלגוריתם BSBI.

---

## אינדוקס מבוזר (Distributed indexing)

- עבור אינדוקס בקנה מידה של הרשת (web-scale) חייבים להשתמש באשכול מחשוב מבוזר.

- מכונות בודדות נוטות לתקלות.

  - יכולות להאט או להיכשל באופן בלתי צפוי.

- כיצד אנו מנצלים מאגר כזה של מכונות?
  - תשובה: באמצעות ארכיטקטורת מחשוב מבוזרת (כמו MapReduce), בה מכונת מאסטר מנהלת את העבודה ומפצלת את משימת האינדוקס לתתי-משימות המבוצעות במקביל על ידי מכונות ה-worker.

---

## מרכזי נתונים של מנועי חיפוש (Web search engine data centers)

- מרכזי נתונים של חיפוש ברשת (Google, Bing, Baidu) מכילים בעיקר מכונות סטנדרטיות (commodity machines).

- מרכזי הנתונים מפוזרים ברחבי העולם.

- הערכה: לגוגל כ-1 מיליון שרתים, 3 מיליון מעבדים/ליבות (Gartner 2007).

- ביולי 2016 גרטנר העריכו שלגוגל היו באותו זמן 2.5 מיליון שרתים.


---

## מרכזי נתונים עצומים (Massive data centers)

- אם במערכת שאינה עמידה לתקלות עם 1000 צמתים, לכל צומת יש זמן פעולה תקין (uptime) של 99.9%, מהו זמן הפעולה התקין של המערכת?

- תשובה: 36.7%

- הסבר: חישוב ההסתברות שכל הרכיבים יעבדו יחד (בהנחה של אי-תלות) הוא מכפלת ההסתברויות:
  $$ 0.999^{1000} \approx 0.36769 \approx 36.7\% $$


---

## אינדוקס מבוזר - המשך (Distributed indexing)

- תחזוקת מכונת מאסטר (master) המכוונת את עבודת האינדוקס – נחשבת "בטוחה".

- פיצול האינדוקס לקבוצות של משימות (מקביליות).

- מכונת המאסטר מקצה כל משימה למכונה פנויה מתוך מאגר.

---

## משימות מקביליות (Parallel tasks)

- נשתמש בשתי קבוצות של משימות מקביליות:

  - מנתחים (Parsers)

  - הופכים (Inverters)

- נחלק את אוסף המסמכים הקלט לפיצולים (splits).

- כל פיצול הוא תת-קבוצה של מסמכים (מקביל לבלוקים ב-BSBI/SPIMI).

---

## מנתחים (Parsers)

- המאסטר מקצה פיצול למכונת מנתח (parser) פנויה.

- המנתח קורא מסמך אחד בכל פעם ופולט זוגות (term, doc).

- המנתח כותב את הזוגות לתוך $j$ מחיצות (partitions).

- כל מחיצה מיועדת לטווח של האותיות הראשונות של המונחים.

  - (למשל, a-f, g-p, q-z) – כאן $j = 3$.

- כעת להשלמת היפוך האינדקס.

---

## הופכים (Inverters)

- הופך (inverter) אוסף את כל הזוגות (term, doc) (= postings) עבור מחיצת-מונח אחת.

- ממיין וכותב לרשימות postings.

---

## זרימת נתונים (Data flow)

![alt text]({EB06F7C9-91FD-4614-9F6A-4060491A8F86}.png)

התרשים ממחיש את תהליך האינדוקס המבוזר באמצעות גישת MapReduce:

**פירוט השלבים:**
1. **Splits (פיצולים):** אוסף המסמכים מחולק למקטעים (splits), כאשר כל מקטע הוא תת-קבוצה של מסמכים.
2. **Map phase (שלב המיפוי):**
  - כל Parser (מנתח) מקבל פיצול מהמאסטר.
  - כל Parser מעבד את המסמכים, מפרק אותם למונחים (tokens) ומייצר זוגות (term, docID).
  - הזוגות נכתבים לקבצי Segment, כאשר כל קובץ מייצג טווח של מונחים (למשל a-f, g-p, q-z).
3. **Segment files (קבצי מקטע):**
  - כל Parser יוצר מספר קבצים, אחד לכל טווח אותיות.
  - כך מובטח שכל מונח יופיע רק בקובץ אחד, מה שמאפשר עיבוד מקבילי בהמשך.
4. **Reduce phase (שלב הצמצום):**
  - כל Inverter (הופך) מקבל את כל הקבצים של טווח מסוים מכל ה-Parsers.
  - ה-Inverter ממזג, ממיין ובונה את רשימות ה-postings עבור כל מונח בטווח שלו.
  - התוצאה היא קובץ postings ממוין לכל טווח.
5. **Postings:**
  - מתקבלים קבצי postings סופיים, כל אחד עבור טווח מונחים שונה.

**יתרונות הגישה:**
- מאפשר עיבוד מקבילי של כמויות עצומות של מסמכים.
- כל שלב ניתן לחלוקה בין מכונות רבות, מה שמאיץ את תהליך האינדוקס.
- תורם לעמידות בפני תקלות: אם מכונה נופלת, ניתן להקצות מחדש את המשימה.

**סיכום:**
התרשים מדגים כיצד MapReduce מחלק את משימת האינדוקס למנות קטנות, מעבד אותן במקביל, ומאחד את התוצאות לאינדקס הפוך שלם ויעיל.



---

## MapReduce

- אלגוריתם בניית האינדקס שתיארנו כרגע הוא מופע של MapReduce.

- MapReduce (Dean and Ghemawat 2004) היא מסגרת עבודה (framework) חסינה ופשוטה תפיסתית למחשוב מבוזר...

- ... מבלי לכתוב קוד עבור חלק ההפצה (distribution).

- הם מתארים את מערכת האינדוקס של גוגל (בסביבות 2002) כמורכבת ממספר שלבים, שכל אחד מהם מיושם ב-MapReduce.

---

## סכמה לבניית אינדקס ב-MapReduce (Schema for index construction in MapReduce)

- סכמה של פונקציות map ו-reduce:

  - map: input $\rightarrow$ list(k, v)

  - reduce: (k,list(v)) $\rightarrow$ output

- מימוש הסכמה לבניית אינדקס:

  - map: collection $\rightarrow$ list(termID, docID)

  - reduce: (<termID1, list(docID)>, <termID2, list(docID)>, ...) $\rightarrow$ (postings list1, postings list2, ...)

- הסבר: פונקציית ה-Map מקבילה לשלב ה-Parser (יצירת זוגות מונח-מסמך), ופונקציית ה-Reduce מקבילה לשלב ה-Inverter (איסוף כל מסמכי המונח לרשימת postings אחת).

---

## דוגמה לבניית אינדקס (Example for index construction)

- שלב ה-Map:

  - קלט (Input):
    - d1 : C came, C went.
    - d2 : C died.

  - פלט (Output):
    - <C,d1>, <came,d1>, <C,d1>, <went,d1>, <C, d2>, <died,d2>

- שלב ה-Reduce:

  - קלט (Input):
    - (<C,(d1,d2,d1)>, <died,(d2)>, <came,(d1)>, <went,(d1)>)

  - פלט (Output):
    - (<C,(d1:2,d2:1)>, <died,(d2:1)>, <came,(d1:1)>, <went,(d1:1)>)

- הסבר הדוגמה:

  - בשלב ה-Map, המערכת עוברת על המסמכים ויוצרת זוג של (מונח, מזהה מסמך) עבור כל מילה בכל מסמך. שימו לב שהמונח 'C' מופיע פעמיים במסמך d1, ולכן נוצרים שני זוגות <C,d1>.

  - בין שלב ה-Map לשלב ה-Reduce, המערכת מבצעת קיבוץ (shuffling/sorting) כך שכל הערכים השייכים לאותו מפתח (מונח) מגיעים לאותו Reducer.

  - בשלב ה-Reduce, ה-Reducer מקבל את המונח ואת רשימת כל המסמכים בהם הוא הופיע (כולל כפילויות). בדוגמה זו, ה-Reducer סופר את מספר ההופעות של המונח בכל מסמך (Term Frequency) ומייצר רשימת postings סופית עם המידע הזה (למשל, C הופיע פעמיים ב-d1 ופעם אחת ב-d2).

---

## אינדוקס דינמי (Dynamic indexing)

- עד כה, הנחנו שהאוספים הם סטטיים.

- הם לעיתים רחוקות כאלה:

  - מסמכים מגיעים לאורך זמן וצריך להוסיף אותם.

  - מסמכים נמחקים ומשתנים.

- משמעות הדבר היא שיש לשנות את המילון ואת רשימות ה-postings:

  - עדכוני postings עבור מונחים שכבר נמצאים במילון.

  - מונחים חדשים שנוספים למילון.

---

## הגישה הפשוטה ביותר (Simplest approach)

- תחזוקת אינדקס ראשי "גדול".

- מסמכים חדשים נכנסים לאינדקס עזר "קטן".

- חיפוש בשניהם ומיזוג התוצאות.

- מחיקות:

  - וקטור-ביטים (bit-vector) לסימון מסמכים שנמחקו (Invalidation).

  - סינון מסמכים בתוצאות החיפוש באמצעות וקטור-הביטים הזה.

- מדי פעם, ביצוע אינדוקס מחדש (re-index) לאינדקס ראשי אחד.

---

## בעיות עם אינדקסים ראשיים ועזר (Issues with main and auxiliary indexes)

- בעיה של מיזוגים תכופים – "נוגעים" בחומר הרבה.

- ביצועים ירודים במהלך המיזוג.

- למעשה:

  - מיזוג אינדקס העזר לאינדקס הראשי הוא יעיל אם שומרים קובץ נפרד לכל רשימת postings.

  - המיזוג הוא זהה להוספה פשוטה (append).

  - אבל אז נצטרך המון קבצים – לא יעיל למערכת ההפעלה.

- במציאות: משתמשים בסכמה איפשהו באמצע (למשל, פיצול רשימות postings גדולות מאוד, איסוף רשימות postings באורך 1 לקובץ אחד וכו').

---

## בעיות נוספות עם אינדקסים מרובים (Further issues with multiple indexes)

- קשה לתחזק סטטיסטיקות של כל האוסף (Collection-wide statistics).

- למשל, כשדיברנו על תיקון שגיאות כתיב: איזו מבין החלופות המתוקנות נציג למשתמש?

  - אמרנו, בחר את זו עם הכי הרבה פגיעות (hits).

- איך מתחזקים את ה"מובילים" (top ones) עם אינדקסים מרובים ווקטורי-ביטים לביטול (invalidation)?

  - אפשרות אחת: להתעלם מהכל חוץ מהאינדקס הראשי לצורך סידור כזה.

- נראה עוד סטטיסטיקות כאלה בשימוש בדירוג תוצאות.

---

## אינדוקס דינמי בגוגל (Google dynamic indexing)

![alt text]({72BF5F89-FB3D-47B4-BFEE-C58D18826C7D}.png)

- הסבר התרשים:

  - התרשים ממחיש את המעבר של גוגל משיטת אינדוקס ישנה ("old index") למערכת "Caffeine".

  - בצד שמאל, "old index" מוצג כערימה של שכבות או בלוקים צבעוניים. זה מייצג גישה של עיבוד באצוות (batch processing), שבה האינדקס נבנה או מתעדכן בשכבות גדולות, מה שלוקח זמן ויוצר השהיה בין פרסום תוכן להופעתו בחיפוש.

  - החץ מסמן את המעבר לשיטה החדשה.

  - בצד ימין, "Caffeine" מוצג כרשת סבוכה ומקושרת המכילה סוגי מדיה שונים (תמונות, חדשות, ספרים, וידאו). זה מייצג מערכת אינדוקס רציפה (continuous indexing), שבה כל דף או פריט תוכן מעובד ונוסף לאינדקס בנפרד ובמהירות (כמעט בזמן אמת), במקום לחכות לעדכון אצווה גדול.

---

## אינדוקס דינמי במנועי חיפוש (Dynamic indexing at search engines)

- כל מנועי החיפוש הגדולים מבצעים כיום אינדוקס דינמי.

- האינדקסים שלהם עוברים שינויים תוספתיים תכופים.

  - פריטי חדשות, בלוגים, דפי אינטרנט בנושאים חדשים.

    - שרה פיילין, קורונה (COVID-19), ...

- אבל (לפעמים/בדרך כלל) הם גם בונים מחדש את האינדקס מאפס מעת לעת.

  - עיבוד השאילתות מועבר אז לאינדקס החדש, והאינדקס הישן נמחק.

---

## סוגים אחרים של אינדקסים (Other sorts of indexes)

- אינדקסי מיקומים (Positional indexes).

  - אותה בעיית מיון... רק גדולה יותר.

- בניית אינדקסים של n-gram תווים:

  - תוך כדי ניתוח הטקסט, מונים את ה-n-grams.

  - לכל n-gram, צריך מצביעים לכל מונחי המילון המכילים אותו – ה-"postings".

  - שימו לב שאותה "רשומת postings" תופיע שוב ושוב בעת ניתוח המסמכים – צריך גיבוב (hashing) יעיל כדי לעקוב אחרי זה.

    - למשל, שהטריגרמה *uou* מופיעה במונח **deciduous** תתגלה בכל הופעה בטקסט של **deciduous**.

  - צריך לעבד כל מונח רק פעם אחת.

---




</div>
