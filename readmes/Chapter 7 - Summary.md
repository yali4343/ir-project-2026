<link rel="stylesheet" href="pdf_rtl_styles.css">

<style>
body, div, p, li, ul, ol { direction: rtl; text-align: right; }
</style>

# סיכום פרק 7 - חישוב ציונים במערכת חיפוש מלאה <span dir="ltr">(Computing Scores in a Complete Search System)</span>

<div dir="rtl">

סיכום זה מכסה את פרק 7 העוסק בארכיטקטורה של מנוע חיפוש שלם, תוך התמקדות בשיטות לחישוב יעיל של ציוני רלוונטיות (Scoring), דירוג (Ranking), ושימוש ברכיבים שונים כמו אינדקסים מדורגים וניתוח שאילתות.

---

## עמוד 1: עמוד שער
**נושא:** כותרת וזכויות יוצרים

עמוד זה מכיל את פרטי ההוצאה לאור (Cambridge University Press) ושנת ההוצאה (2009). זהו עמוד הפתיחה של המסמך.

---

## עמוד 2: מבוא לחישוב ציונים וחיפוש יעיל
**נושא:** חישוב ציונים ומבוא לייעול <span dir="ltr">(Efficient Scoring)</span>

פרק זה מתבסס על עקרונות שקלול מונחים (Term Weighting) ומודל המרחב הווקטורי (Vector Space Model) שהוצגו בפרק 6. המטרה כעת היא לבנות מערכת חיפוש מלאה ויעילה.

*   **הבעיה:** חישוב מלא של Cosine Similarity עבור כל מסמך באוסף הוא יקר מדי מבחינה חישובית.
*   **הפתרון:** שימוש בהיוריסטיקות (Heuristics) כדי להאיץ את החישוב.
    *   המחיר: ייתכן שלא נמצא בדיוק את ה-K המסמכים הטובים ביותר, אלא קירוב טוב שלהם.
*   **מבנה הפרק:**
    1.  **סעיף 7.1:** היוריסטיקות לדירוג מהיר (Efficient Scoring and Ranking).
    2.  **סעיף 7.2:** רכיבי מנוע חיפוש מלא (כולל אינדקסים מתקדמים, קרבה בין מונחים).
    3.  **סעיף 7.3:** אינטראקציה בין מודל המרחב הווקטורי לאופרטורים אחרים (כגון שאילתות בוליאניות).

### חישוב Cosine Similarity יעיל
הטקסט מתייחס לאלגוריתם בסיסי (Recap מפרק 6, איור 6.14).
נניח שאילתה $q$: `jealous gossip`.
1.  **וקטור השאילתה $v(q)$:** מכיל רק שני רכיבים שאינם אפס.
2.  **משקל:** בהנחה שאין משקל ייחודי למונחי השאילתה, הרכיבים שווים (למשל 0.707 כל אחד).

**עקרון הדירוג היחסי:**
אנחנו מתעניינים בציון ה*יחסי* (Relative Score) של המסמכים ולא בערך המוחלט. לכן:
*   מספיק לחשב דמיון מול וקטור שאילתה שבו כל הרכיבים הם 1 (כלומר $V(q)$ במקום $v(q)$ המנורמל).
*   היחס נשמר: אם מסמך $d1$ מקבל ציון גבוה יותר מ-$d2$ מול $V(q)$, הוא יקבל ציון גבוה יותר גם מול $v(q)$.
$$ \vec{V}(q) \cdot \vec{v}(d_1) > \vec{V}(q) \cdot \vec{v}(d_2) \iff \vec{v}(q) \cdot \vec{v}(d_1) > \vec{v}(q) \cdot \vec{v}(d_2) $$
משמעות הדבר היא שניתן לחשב את הציון כסכום משוקלל של משקלי המונחים במסמך, עבור המונחים שמופיעים בשאילתה.

---

## עמוד 3: אלגוריתם לדירוג מהיר
**נושא:** Fast Cosine Score

המוקד כאן הוא ייעול האלגוריתם לחישוב ציוני Cosine.

### איור 7.1: אלגוריתם מהיר לציוני מרחב וקטורי
האלגוריתם המוצג (FastCosineScore) פועל בצורה הבאה:
1.  **אתחול:** מערך ציונים ($Scores$) מאופס לכל המסמכים.
2.  **מעבר על מונחי השאילתה:** לכל מונח $t$ בשאילתה $q$:
    *   מחשבים את המשקל שלו בשאילתה $w_{t,q}$.
    *   שולפים את רשימת המופעים (Postings List) של $t$.
    *   לכל מסמך $d$ ברשימה, מוסיפים לציון שלו את המכפלה של משקל המונח במסמך ($wf_{t,d}$) ומשקל המונח בשאילתה. (בגרסה מפושטת, אם $w_{t,q}=1$, פשוט מוסיפים את $wf_{t,d}$).
3.  **נרמול:** בסוף המעבר על כל המונחים, מחלקים את הציון המצטבר של כל מסמך באורך המסמך ($Length[d]$) כדי לקבל את ה-Cosine Similarity.
4.  **בחירת המובילים:** מחזירים את $K$ המסמכים עם הציון הגבוה ביותר.

<br><br><br><br><br>

**נקודות מפתח:**
*   **חיסכון בחישוב:** אנו מחשבים ציון רק למסמכים שמכילים *לפחות אחד* ממונחי השאילתה (בניגוד לכל $N$ המסמכים באוסף).
*   **מבנה נתונים - ערימה (Heap):** כדי לבחור את $K$ הטובים ביותר מתוך $J$ מסמכים בעלי ציון חיובי:
    *   בניית הערימה: $2J$ פעולות השוואה.
    *   שליפת $K$ המסמכים: $K \log J$ פעולות.
    *   זה יעיל יותר ממיון מלא של כל המסמכים.

---

## עמוד 4: שליפת K מסמכים לא-מדויקת <span dir="ltr">(Inexact Top K Retrieval)</span>
**נושא:** היוריסטיקות לקיצוץ בעלויות חישוב

עד כה שאפנו למצוא *בדיוק* את ה-$K$ הגבוהים ביותר. כעת נעבור לגישה של "מספיק טוב":
*   **המטרה:** למצוא $K$ מסמכים שסביר להניח שהם *בין* הגבוהים ביותר, תוך הוזלה משמעותית של עלות החישוב.
*   **ההצדקה:** מדד ה-Cosine הוא ממילא רק קירוב לרלוונטיות האמיתית בעיני המשתמש. קירוב של הקירוב לא צפוי לפגוע משמעותית בחוויית המשתמש.
*   **הבעיה העיקרית:** חישוב ציון למספר עצום של מסמכים המכילים מונחי שאילתה נפוצים.

### התהליך הדו-שלבי של ההיוריסטיקות:
1.  **מציאת מועמדים (Candidates):** איתור קבוצה מצומצמת $A$ של מסמכים שהם מועמדים פוטנציאליים.
    *   הגודל של $A$ צריך להיות גדול מ-$K$ אך קטן משמעותית מ-$N$ ($K < |A| \ll N$).
2.  **דירוג סופי:** חישוב ציון Cosine מדויק רק עבור המסמכים בקבוצה $A$, והחזרת ה-$K$ הטובים מביניהם.

רוב ההיוריסטיקות הללו מתאימות לשאילתות טקסט חופשי (Free Text) ופחות לשאילתות בוליאניות או שאילתות ביטוי (Phrase Queries).

---

## עמוד 5: אלימינציה של אינדקס ורשימות אלופים <span dir="ltr">(Index Elimination & Champion Lists)</span>
**נושא:** סינון מוקדם של מסמכים

### 7.1.2 אלימינציה של אינדקס (Index Elimination)
הרעיון הוא לא להתחשב בכל המסמכים המכילים מונח כלשהו מהשאילתה, אלא לסנן:
1.  **סינון לפי IDF:**
    *   מתעלמים ממונחים בעלי IDF נמוך (מילים נפוצות שאינן תורמות הרבה להבחנה).
    *   משתמשים רק במונחים שה-IDF שלהם עובר סף מסוים.
    *   **דוגמה:** עבור השאילתה `catcher in the rye`, נתעלם מ-`in` ו-`the` ונתמקד רק ב-`catcher` ו-`rye`.
    *   חסכון: רשימות ה-Postings של מילים נפוצות הן ארוכות מאוד; הדילוג עליהן חוסך עבודת מעבד ודיסק רבה.
2.  **דרישת מופעים רבים:**
    *   שוקלים רק מסמכים שמכילים *רבים* ממונחי השאילתה (או את כולם).
    *   סכנה: ייתכן שנקבל פחות מ-$K$ תוצאות אם התנאים מחמירים מדי.

### 7.1.3 רשימות אלופים (Champion Lists)
ידוע גם בשם "Fancy Lists" או "Top Docs".
*   **הרעיון:** לכל מונח $t$ במילון, מחשבים מראש (בזמן בניית האינדקס) את $r$ המסמכים בעלי המשקל הגבוה ביותר עבור מונח זה.
*   **קבוצת המועמדים $A$:** בעת שאילתה, בונים את הגרסה המאוחדת של רשימות האלופים של מונחי השאילתה.
    *   מחשבים ציון Cosine מלא רק למסמכים שנמצאים באיחוד זה.
*   **הפרמטר $r$:** נקבע מראש בזמן האינדוקס. בחירה שלו היא קריטית ותלויה באפליקציה. החיסרון הוא שהוא סטטי, בעוד ש-$K$ (מספר התוצאות המבוקש) עשוי להשתנות משאילתה לשאילתה.

---

## עמוד 6: ציוני איכות סטטיים <span dir="ltr">(Static Quality Scores)</span>
**נושא:** שילוב מדדים שאינם תלויי-שאילתה

במנועי חיפוש רבים יש מדד איכות למסמך שאינו קשור לשאילתה הספציפית:
*   **ציוני איכות סטטיים ($g(d)$):** מספר בין 0 ל-1 המייצג את "טיב" המסמך.
    *   דוגמאות: פופולריות (מספר צפיות), ביקורות חיוביות, PageRank (באינטרנט).
*   **שקלול הציון הסופי (Net Score):** שילוב הציון הסטטי עם הציון הקוסמטי (תלוי השאילתה).
    *   נוסחה אפשרית (סכום פשוט):
    $$ \text{net-score}(q, d) = g(d) + \frac{\vec{V}(q) \cdot \vec{V}(d)}{|\vec{V}(q)| |\vec{V}(d)|} $$
    *   ניתן לתת משקלים שונים לכל רכיב בנוסחה.

### סידור מחדש של ה-Postings Lists
כדי לייעל את השליפה עם ציוני איכות:
*   ממיינים את רשימות ה-Postings לפי הציון הסטטי $g(d)$ (בסדר יורד) במקום לפי מזהה מסמך (DocID).
*   **היתרון:** מאפשר לסרוק את המסמכים ה"איכותיים" ביותר תחילה ולעצור מוקדם יותר, מתוך הנחה שהם יהיו רלוונטיים יותר בציון הכולל.

<br><br><br><br><br>

איור 7.2 מראה רשימות שבהן המסמכים מסודרים לפי $g(d)$. הסריקה יכולה להתבצע בצורה יעילה בדומה לחיתוך רשימות רגיל.

---

## עמוד 7: רשימות אלופים גלובליות ורשימות גבוה/נמוך
**נושא:** הרחבת רשימות האלופים

### רשימות אלופים גלובליות (Global Champion Lists)
*   עבור כל מונח $t$, שומרים רשימה של $r$ מסמכים בעלי הציון המשולב הגבוה ביותר: $g(d) + \text{tf-idf}_{t,d}$.
*   החישוב מתבצע בזמן האינדוקס. בזמן שאילתה, מתמקדים רק במסמכים אלו.

### רשימות גבוהות ונמוכות (High/Low Lists)
רעיון נוסף לייעול:
*   לכל מונח, מחזיקים שתי רשימות נפרדות:
    1.  **רשימה גבוהה (High):** מכילה את $m$ המסמכים המובילים עבור המונח (לפי משקל).
    2.  **רשימה נמוכה (Low):** מכילה את כל שאר המסמכים המכילים את המונח.
*   **תהליך החיפוש:**
    1.  סורקים תחילה את הרשימות הגבוהות של מונחי השאילתה.
    2.  מחשבים ציונים.
    3.  אם נמצאו $K$ תוצאות מספקות – עוצרים.
    4.  אם לא – ממשיכים לסרוק את הרשימות הנמוכות.

---

## עמוד 8: סידור לפי השפעה <span dir="ltr">(Impact Ordering)</span>
**נושא:** Term-at-a-time Scoring

בשיטות הקודמות (כמו סידור לפי DocID או ציון סטטי), הסדר היה עקבי בין כל הרשימות, מה שאפשר חישוב מקבילי (Document-at-a-time). כעת נבחן גישה אחרת.

### סידור לפי TF (Impact Ordering)
*   בכל רשימת postings, המסמכים מסודרים לפי ערך ה-tf ($tf_{t,d}$) בסדר יורד.
*   **המשמעות:** הסדר אינו אחיד בין רשימות של מונחים שונים. לא ניתן לבצע סריקה מקבילה פשוטה.
*   **שיטת החישוב:** חייבים להשתמש בגישת **Term-at-a-time** (צבירת ציונים מונח אחר מונח).

**אופטימיזציות בשיטה זו:**
1.  **עצירה מוקדמת (Pre-computation stop):** כשסורקים רשימה של מונח $t$, מפסיקים אחרי $r$ מסמכים או כשערך ה-tf יורד מתחת לסף מסוים.
2.  **סדר עיבוד המונחים:** מעבדים את מונחי השאילתה לפי סדר IDF יורד (מתחילים מהמילים הנדירות והחשובות ביותר).
    *   המונחים הראשונים תורמים הכי הרבה לציון.
    *   אם התרומה של מונחים מאוחרים זניחה, ניתן לדלג עליהם לחלוטין.

---

## עמוד 9: גיזום אשכולות <span dir="ltr">(Cluster Pruning)</span>
**נושא:** שיטה מבוססת קלסטרינג לצמצום מרחב החיפוש

זוהי שיטה הכוללת שלב מקדים (Preprocessing) ושלב חיפוש (Query Time).

### שלב העיבוד המקדים:
1.  בוחרים באקראי $\sqrt{N}$ מסמכים מהאוסף שישמשו כ**מנהיגים (Leaders)**.
2.  כל שאר המסמכים באוסף מוגדרים כ**עוקבים (Followers)**.
3.  לכל "עוקב", מוצאים את המנהיג הקרוב אליו ביותר (לפי דמיון וקטורי) ומשייכים אותו לאשכול שלו.
    *   בממוצע, לכל מנהיג יהיו כ-$\sqrt{N}$ עוקבים.

### שלב השאילתה:
1.  עבור שאילתה $q$, מוצאים את המנהיג $L$ הקרוב ביותר לשאילתה (על ידי השוואה מול כל $\sqrt{N}$ המנהיגים).
2.  קבוצת המועמדים $A$ כוללת את המנהיג $L$ ואת כל העוקבים שלו.
3.  מחשבים ציון Cosine מדויק רק עבור המסמכים בקבוצה $A$.

<br><br><br><br><br>

איור 7.3 ממחיש את המרחב הווקטורי המחולק לאשכולות סביב מנהיגים.

**וריאציות:**
*   ניתן לשייך עוקב ל-$b1$ מנהיגים קרובים (ולא רק אחד).
*   ניתן לבדוק בשאילתה את $b2$ המנהיגים הקרובים ביותר (ולא רק אחד).
*   הגדלת $b1$ ו-$b2$ משפרת את הדיוק אך מגדילה את עלות החישוב.

---

## עמוד 10: תרגילים 7.1 - 7.4
**נושא:** תרגול והעמקה

עמוד זה מכיל שאלות חזרה המחדדות את ההבנה של הנושאים שנלמדו:
*   **תרגיל 7.1:** מדוע במיון לפי איכות סטטית משתמשים בסדר יורד? (כדי לפגוש את המסמכים הטובים ביותר כבר בהתחלה).
*   **תרגיל 7.2:** ההבדל בין Champion Lists רגילות (לפי tf) לגלובליות (לפי שילוב tf-idf ואיכות סטטית).
*   **תרגיל 7.3:** יעילות במקרה של שאילתות בנות מילה אחת.
*   **תרגיל 7.4:** כיצד סידור גלובלי אחיד עוזר ליעילות (מאפשר סריקה מקבילה/חיתוך מהיר).

---

## עמוד 11: תרגילים ורכיבי מערכת <span dir="ltr">(Tiered Indexes)</span>
**נושא:** תרגילי המשך ואינדקסים מדורגים - סעיף 7.2

### 7.2.1 אינדקסים מדורגים (Tiered Indexes)
כאשר משתמשים בהיוריסטיקות כמו אלימינציה, ייתכן מצב שבו נשארים עם מעט מדי תוצאות (פחות מ-$K$).
פתרון: שימוש ב**אינדקסים מדורגים**.
*   זהו הכללה של רשימות אלופים.
*   מחלקים את האינדקס לכמה רמות (Tiers) בהתבסס על סף חשיבות (למשל סף tf).

**מבנה המדרג (דוגמה):**
*   **Tier 1 (מדרגה ראשונה):** מכיל רק הפניות למסמכים שבהם ה-tf של המונח גבוה מאוד (למשל > 20).
*   **Tier 2 (מדרגה שנייה):** מכיל הפניות עם tf בינוני (למשל > 10).
*   **Tier 3 (מדרגה שלישית):** מכיל את כל השאר.

**תהליך החיפוש:**
1.  מתחילים לחפש ב-Tier 1.
2.  אם נמצאו מספיק תוצאות ($K$) – עוצרים.
3.  אם לא – "נופלים" (Fall back) ל-Tier 2 ומחפשים גם שם, וכן הלאה.

---

## עמוד 12: המחשת אינדקסים מדורגים וקרבת מונחים
**נושא:** איור 7.4 וקרבת מונחים

<br><br><br><br><br>

איור 7.4 מראה חלוקה של מסמכים (כמו בדוגמה מפרק 6) ל-Tier 1 ו-Tier 2 בהתבסס על ספי תדר מונח.

### 7.2.2 קרבה של מונחי שאילתה (Query-Term Proximity)
בחיפוש טקסט חופשי, במיוחד באינטרנט, יש חשיבות רבה למרחק בין מילות השאילתה במסמך.
*   משתמשים מעדיפים מסמכים שבהם המונחים מופיעים צפוף וקרוב זה לזה (למשל, ביטוי שלם).
*   **חלון ($\omega$):** רוחב החלון המינימלי במסמך המכיל את כל מונחי השאילתה.
    *   למשל: למשפט "The quality of mercy is not strained", עבור השאילתה `strained mercy`, החלון הקטן ביותר הוא בגודל 4 מילים (mercy is not strained).
*   ככל ש-$\omega$ קטן יותר, המסמך נחשב רלוונטי יותר.
*   ניתן להתייחס ל-$\omega$ כאל פרמטר נוסף ("Feature") בפונקציית הדירוג המשוקללת.

---

## עמוד 13: תכנון פונקציות דירוג וצבירת ראיות
**נושא:** Parsing and Scoring Functions

### 7.2.3 תכנון פונקציות פענוח ודירוג (Parsing & Scoring)
ממשקי חיפוש מודרניים מסתירים מהמשתמש את הסיבוכיות של אופרטורים בוליאניים, ומאפשרים הקלדת טקסט חופשי. המערכת צריכה לתרגם זאת לשאילתות חכמות.
**דוגמה ל-Query Parser:**
עבור שאילתה `rising interest rates`:
1.  נסיון ראשון: הרצת השאילתה כביטוי (Phrase Query) "rising interest rates".
2.  אם יש מעט תוצאות: פיצול לביטויים קטנים יותר ("rising interest", "interest rates").
3.  אם עדיין חסר: הרצת המילים בנפרד (Vector Space).

**צבירת ראיות (Evidence Accumulation):**
מסמך יכול לעלות בתוצאות מכמה שלבים שונים. הציון הסופי צריך לשקלל ראיות ממקורות שונים:
*   דמיון וקטורי (Vector Space).
*   איכות סטטית (Static Quality).
*   קרבה (Proximity).
*   מיקום בכותרת/זונים (Zones).

את המשקל של כל רכיב קשה לקבוע ידנית ("Hand Coding"). במערכות מודרניות, ובעיקר באינטרנט, משתמשים ב**למידת מכונה (Machine Learning)** כדי ללמוד את פונקציית הדירוג האופטימלית (Machine-Learned Ranking - MLR).

---

## עמוד 14: המערכת השלמה <span dir="ltr">(Putting it all together)</span>
**נושא:** ארכיטקטורה מלאה של מנוע חיפוש

### 7.2.4 חיבור כל החלקים
איור 7.5 מציג דיאגרמה של מערכת חיפוש מלאה.

<br><br><br><br><br>

**זרימת המידע (Data Flow):**
1.  **אינדוקס (שמאל):** מסמכים נכנסים, עוברים עיבוד לשוני (Tokenization, Stemming).
    *   הטוקנים נשמרים ב**אינדקסים** (כולל Tiered, Positional, Zone).
    *   הטקסט המקורי נשמר ב-**Document Cache** לצורך יצירת תקצירים (Snippets) בתוצאות.
2.  **שאילתה (למעלה):** המשתמש מזין שאילתה.
    *   בדיקת איות (Spelling Correction).
    *   השאילתה נשלחת לאינדקסים.
3.  **שליפה ודירוג:**
    *   שליפת מסמכים רלוונטיים.
    *   חישוב ציונים במודול **Scoring** (משתמש ב-MLR).
4.  **הצגה:** יצירת דף תוצאות עם כותרות ותקצירים.

---

## עמוד 15: אינטראקציה בין אופרטורים ווקטורים
**נושא:** סעיף 7.3 - וקטורים מול אופרטורים אחרים

המערכת צריכה לתמוך גם בחיפוש וקטורי וגם באופרטורים כמו Boolean, Wildcard.
ישנו מתח בין הגישות:
*   **חיפוש וקטורי:** מבוסס על צבירת ראיות (ככל שיש יותר מילים, הציון עולה). סמנטיקה של "soft conjunction" (רצוי שיהיו כל המילים, אבל לא חובה).
*   **חיפוש בוליאני:** מבוסס על קסמים לוגיים קשיחים (AND, OR, NOT). אין משמעות ל"כמעט". אינו כולל דירוג באופן טבעי.

לא קל לשלב ביניהם במערכת אחת בצורה שקופה למשתמש. המודל הווקטורי לא תמיד יודע לענות על שאילתות בוליאניות בצורה טבעית.

---

## עמוד 16: שאילתות Wildcard ו-Phrase
**נושא:** המשך אינטראקציה עם אופרטורים

### Wildcard Queries
שאילתות כמו `rom*` דורשות טיפול מיוחד.
*   ניתן לפרש זאת כ"הוספת כל המילים המתאימות לשאילתה הווקטורית".
*   למשל: `rome` ו-`roman` יוספו לווקטור השאילתה. מסמך המכיל את שתיהן יקבל ציון גבוה יותר ממסמך המכיל רק אחת.

### Phrase Queries
הייצוג הווקטורי הוא **Lossy** (מאבד מידע): סדר המילים הולך לאיבוד.
*   אינדקס וקטורי רגיל לא יכול לתמוך בשאילתות ביטוי מדויקות ("German Shepherd").
*   הוא יכול למצוא מסמכים עם משקל גבוה ל-`German` ול-`Shepherd`, אך לא להבטיח שהם צמודים.
*   לכן, נדרש מנגנון נפרד (כמו אינדקס מיקום - Positional Index) לטיפול בביטויים, המשולב לעיתים כשלב סינון או דירוג נוסף מעל החיפוש הווקטורי.

---

## עמוד 17: ביבליוגרפיה וקריאה נוספת
**נושא:** מקורות (Section 7.4)

עמוד זה מכיל הפניות למאמרים ולמחקרים שהיוו את הבסיס לשיטות שהוצגו בפרק:
*   מאמרים על Optimizations ו-Index Pruning.
*   מקורות על Champion Lists (Top Docs).
*   מחקרים על Cluster Pruning.
*   עבודות חלוציות בתחום ה-Learning to Rank (שימוש ב-ML לדירוג).

</div>
