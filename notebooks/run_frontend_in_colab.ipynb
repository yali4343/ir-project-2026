{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# Add the src directory to the path so we can import search_frontend\n",
    "# Assuming the notebook is in 'notebooks/' and src is in '../src/'\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Also add the current directory just in case\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "# Set Google Application Credentials for local execution\n",
    "if not IS_COLAB:\n",
    "    key_path = os.path.join(project_root, 'data', 'extreme-wind-480314-f5-e88363037125.json')\n",
    "    if os.path.exists(key_path):\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path\n",
    "        print(f\"Set GOOGLE_APPLICATION_CREDENTIALS to {key_path}\")\n",
    "    else:\n",
    "        print(\"Warning: Service account key not found in data/ folder.\")\n",
    "\n",
    "# Install dependencies if running locally and they might be missing\n",
    "if not IS_COLAB:\n",
    "    print(\"Running locally. Ensuring dependencies are installed...\")\n",
    "    # !pip install -q nltk flask google-cloud-storage pandas requests gcsfs pyarrow\n",
    "else:\n",
    "    print(\"Running in Colab.\")\n",
    "    !pip install -q gcsfs pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCPDHP7zTQJZ",
    "outputId": "c75f4593-706c-4d2d-ddca-b3261fb845e2"
   },
   "outputs": [],
   "source": [
    "# download nltk stopwords\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAt6KT8xOgHH",
    "outputId": "0c67a9ce-b162-49b9-b614-8c6d895b9fa8"
   },
   "outputs": [],
   "source": [
    "# Install a particular version of `google-cloud-storage` because (oddly enough)\n",
    "# the  version on Colab and GCP is old. A dependency error below is okay.\n",
    "if IS_COLAB:\n",
    "    !pip install -q google-cloud-storage==1.43.0\n",
    "else:\n",
    "    print(\"Skipping GCS downgrade for local environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oKFly5jFLFn"
   },
   "outputs": [],
   "source": [
    "# authenticate below for Google Storage access as needed\n",
    "# Only run this if in Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab, skipping Google Auth (assuming local credentials are set up).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download auxiliary files from bucket if they exist\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "FILES_TO_DOWNLOAD = [\n",
    "    'id_to_title.pkl',\n",
    "    'page_rank.pkl',\n",
    "    'page_views.pkl',\n",
    "    'doc_lengths.pkl',\n",
    "    'doc_norm_text.pkl',\n",
    "    'text_idf.pkl'\n",
    "]\n",
    "\n",
    "if IS_COLAB or os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'):\n",
    "    try:\n",
    "        bucket_name = 'yali-ir2025-bucket'\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        \n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "\n",
    "        for filename in FILES_TO_DOWNLOAD:\n",
    "            blob = bucket.blob(filename)\n",
    "            if blob.exists():\n",
    "                print(f\"Downloading {filename}...\")\n",
    "                blob.download_to_filename(filename)\n",
    "                # Also copy to data/ just in case\n",
    "                import shutil\n",
    "                shutil.copy(filename, f'data/{filename}')\n",
    "            else:\n",
    "                print(f\"{filename} not found in bucket. Skipping.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading files: {e}\")\n",
    "else:\n",
    "    print(\"No credentials. Skipping file downloads.\")\n",
    "\n",
    "# Ensure we have at least dummy data for doc_lengths to prevent ZeroDivisionError\n",
    "import pickle\n",
    "if not os.path.exists('doc_lengths.pkl') and not os.path.exists('data/doc_lengths.pkl'):\n",
    "    print(\"Creating dummy doc_lengths.pkl to prevent ZeroDivisionError...\")\n",
    "    dummy_dl = {1: 1} # At least one document\n",
    "    with open('doc_lengths.pkl', 'wb') as f:\n",
    "        pickle.dump(dummy_dl, f)\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    import shutil\n",
    "    shutil.copy('doc_lengths.pkl', 'data/doc_lengths.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dW0y91OVu5J"
   },
   "source": [
    "# Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7opNkV6uRHIv"
   },
   "outputs": [],
   "source": [
    "# Import the frontend module\n",
    "# Ensure you have 'src' in your python path (see cell above)\n",
    "try:\n",
    "    import search_frontend as se\n",
    "except ImportError:\n",
    "    # Fallback if running from a different directory context\n",
    "    from src import search_frontend as se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTGXXYEXV5l8"
   },
   "outputs": [],
   "source": [
    "# uncomment the code below and execute to reload the module when you make\n",
    "# changes to search_frontend.py (after you upload again).\n",
    "# import importlib\n",
    "# importlib.reload(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "k7K7oFlfVhm5",
    "outputId": "8f31e64f-e631-4dca-a182-ea283cf9ecf0"
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import requests\n",
    "\n",
    "PORT = 8080\n",
    "\n",
    "def run_server():\n",
    "    # Run the app\n",
    "    # Note: use_reloader=False is important in notebooks/background threads\n",
    "    try:\n",
    "        se.app.run(host='0.0.0.0', port=PORT, debug=False, use_reloader=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Server failed to start: {e}\")\n",
    "\n",
    "# Start the server in a background thread\n",
    "print(f\"Starting server on port {PORT}...\")\n",
    "server_thread = threading.Thread(target=run_server)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(3) \n",
    "\n",
    "# Check if server is up\n",
    "if IS_COLAB:\n",
    "    from google.colab.output import eval_js\n",
    "    server_url = eval_js(f\"google.colab.kernel.proxyPort({PORT})\")\n",
    "    print(f\"Colab Server URL: {server_url}\")\n",
    "else:\n",
    "    server_url = f\"http://127.0.0.1:{PORT}\"\n",
    "    print(f\"Local Server URL: {server_url}\")\n",
    "\n",
    "try:\n",
    "    # Simple health check\n",
    "    requests.get(server_url)\n",
    "    print(\"Server is up and running!\")\n",
    "except:\n",
    "    print(\"Warning: Server might not be reachable yet or failed to start.\")\n",
    "\n",
    "print(f\"Test URL: {server_url}/search_body?query=hello+world\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na0MC_1nzDbi"
   },
   "source": [
    "# Testing your app\n",
    "\n",
    "Once your app is running you can query it. You can simply do that by clicking on the URL printed above (the one looking like https://XXXXX-5000-colab.googleusercontent.com/search?query=hello+world or by issuing an HTTP request through code (from colab).\n",
    "\n",
    "The code below shows how to issue a query from python. This is also how our testing code will issue queries to your search engine, so make sure to test your search engine this way after you deploy it to GCP and before submission. Command line instructions for deploying your search engine to GCP are available at `run_frontend_in_gcp.sh`. Note that we will not only issue training queries to your search engine, but also test queries, i.e. queries that you've never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM5ePrRHojbG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Path to queries file\n",
    "# Try 'data/queries_train.json' (relative to project root) or just 'queries_train.json'\n",
    "queries_path = os.path.join(project_root, 'data', 'queries_train.json')\n",
    "if not os.path.exists(queries_path):\n",
    "    queries_path = 'queries_train.json' # Fallback\n",
    "\n",
    "print(f\"Loading queries from: {queries_path}\")\n",
    "with open(queries_path, 'rt') as f:\n",
    "  queries = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWimZWCOy3Ei"
   },
   "outputs": [],
   "source": [
    "def average_precision(true_list, predicted_list, k=40):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    precisions = []\n",
    "    for i,doc_id in enumerate(predicted_list):\n",
    "        if doc_id in true_set:\n",
    "            prec = (len(precisions)+1) / (i+1)\n",
    "            precisions.append(prec)\n",
    "    if len(precisions) == 0:\n",
    "        return 0.0\n",
    "    return round(sum(precisions)/len(precisions),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geHKyFB4xkBe"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(predicted_list) == 0:\n",
    "        return 0.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(predicted_list), 3)\n",
    "def recall_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(true_set) < 1:\n",
    "        return 1.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(true_set), 3)\n",
    "def f1_at_k(true_list, predicted_list, k):\n",
    "    p = precision_at_k(true_list, predicted_list, k)\n",
    "    r = recall_at_k(true_list, predicted_list, k)\n",
    "    if p == 0.0 or r == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p + 1.0/r), 3)\n",
    "def results_quality(true_list, predicted_list):\n",
    "    p5 = precision_at_k(true_list, predicted_list, 5)\n",
    "    f1_30 = f1_at_k(true_list, predicted_list, 30)\n",
    "    if p5 == 0.0 or f1_30 == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p5 + 1.0/f1_30), 3)\n",
    "\n",
    "assert precision_at_k(range(10), [1,2,3] , 2) == 1.0\n",
    "assert recall_at_k(   range(10), [10,5,3], 2) == 0.1\n",
    "assert precision_at_k(range(10), []      , 2) == 0.0\n",
    "assert precision_at_k([],        [1,2,3],  5) == 0.0\n",
    "assert recall_at_k(   [],        [10,5,3], 2) == 1.0\n",
    "assert recall_at_k(   range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       [],        [1,2,3],  5) == 0.0\n",
    "assert f1_at_k(       range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       range(10), [0,1,2],  2) == 0.333\n",
    "assert f1_at_k(       range(50), range(5), 30) == 0.182\n",
    "assert f1_at_k(       range(50), range(10), 30) == 0.333\n",
    "assert f1_at_k(       range(50), range(30), 30) == 0.75\n",
    "assert results_quality(range(50), range(5))  == 0.308\n",
    "assert results_quality(range(50), range(10)) == 0.5\n",
    "assert results_quality(range(50), range(30)) == 0.857\n",
    "assert results_quality(range(50), [-1]*5 + list(range(5,30))) == 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYmNTq9u0ChK"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import time\n",
    "\n",
    "# Use the server_url defined in the previous cell\n",
    "# If it's not defined, fallback to localhost\n",
    "if 'server_url' not in locals():\n",
    "    server_url = 'http://127.0.0.1:8080'\n",
    "\n",
    "print(f\"Testing against: {server_url}\")\n",
    "\n",
    "qs_res = []\n",
    "for q, true_wids in queries.items():\n",
    "  duration, ap = None, None\n",
    "  t_start = time()\n",
    "  try:\n",
    "    # Note: Using /search_body for now as that's what we implemented\n",
    "    # The original code used /search. You can change this back later.\n",
    "    res = requests.get(server_url + '/search_body', {'query': q}, timeout=35)\n",
    "    duration = time() - t_start\n",
    "    if res.status_code == 200:\n",
    "      # The response is a list of (doc_id, title)\n",
    "      # We need just the doc_ids for evaluation\n",
    "      results = res.json()\n",
    "      pred_wids = [str(doc_id) for doc_id, title in results]\n",
    "      \n",
    "      # Calculate quality metrics\n",
    "      rq = results_quality(true_wids, pred_wids)\n",
    "      ap = average_precision(true_wids, pred_wids)\n",
    "      \n",
    "      print(f\"Query: {q} | Duration: {duration:.3f}s | Quality: {rq} | AP: {ap}\")\n",
    "    else:\n",
    "        print(f\"Query: {q} | Failed with status {res.status_code}\")\n",
    "  except Exception as e:\n",
    "    print(f\"Query: {q} | Error: {e}\")\n",
    "\n",
    "  qs_res.append((q, duration, ap))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
