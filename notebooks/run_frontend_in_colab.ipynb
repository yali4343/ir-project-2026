{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T20:05:33.944618300Z",
     "start_time": "2026-01-03T20:05:33.874397300Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# Add the src directory to the path so we can import search_frontend\n",
    "# Assuming the notebook is in 'notebooks/' and src is in '../src/'\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Also add the current directory just in case\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "# Set Google Application Credentials for local execution\n",
    "if not IS_COLAB:\n",
    "    key_path = os.path.join(project_root, 'data', 'extreme-wind-480314-f5-e88363037125.json')\n",
    "    if os.path.exists(key_path):\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path\n",
    "        print(f\"Set GOOGLE_APPLICATION_CREDENTIALS to {key_path}\")\n",
    "    else:\n",
    "        print(\"Warning: Service account key not found in data/ folder.\")\n",
    "\n",
    "# Install dependencies if running locally and they might be missing\n",
    "if not IS_COLAB:\n",
    "    print(\"Running locally. Ensuring dependencies are installed...\")\n",
    "    # !pip install -q nltk flask google-cloud-storage pandas requests gcsfs pyarrow\n",
    "else:\n",
    "    print(\"Running in Colab.\")\n",
    "    !pip install -q gcsfs pyarrow"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set GOOGLE_APPLICATION_CREDENTIALS to C:\\Users\\User\\Desktop\\סמסטר א\\אחזור מידע\\פרויקט\\data\\extreme-wind-480314-f5-e88363037125.json\n",
      "Running locally. Ensuring dependencies are installed...\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCPDHP7zTQJZ",
    "outputId": "c75f4593-706c-4d2d-ddca-b3261fb845e2",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:05:43.773491300Z",
     "start_time": "2026-01-03T20:05:43.485102300Z"
    }
   },
   "source": [
    "# download nltk stopwords\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAt6KT8xOgHH",
    "outputId": "0c67a9ce-b162-49b9-b614-8c6d895b9fa8",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:05:45.346574Z",
     "start_time": "2026-01-03T20:05:45.309916200Z"
    }
   },
   "source": [
    "# Install a particular version of `google-cloud-storage` because (oddly enough)\n",
    "# the  version on Colab and GCP is old. A dependency error below is okay.\n",
    "if IS_COLAB:\n",
    "    !pip install -q google-cloud-storage==1.43.0\n",
    "else:\n",
    "    print(\"Skipping GCS downgrade for local environment.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping GCS downgrade for local environment.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-oKFly5jFLFn",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:05:46.858276500Z",
     "start_time": "2026-01-03T20:05:46.816253800Z"
    }
   },
   "source": [
    "# authenticate below for Google Storage access as needed\n",
    "# Only run this if in Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab, skipping Google Auth (assuming local credentials are set up).\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Colab, skipping Google Auth (assuming local credentials are set up).\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T20:05:50.235634900Z",
     "start_time": "2026-01-03T20:05:48.331972500Z"
    }
   },
   "source": [
    "# Download auxiliary files from bucket if they exist\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "FILES_TO_DOWNLOAD = [\n",
    "    'id_to_title.pkl',\n",
    "    'page_rank.pkl',\n",
    "    'page_views.pkl',\n",
    "    'doc_lengths.pkl',\n",
    "    'doc_norm_text.pkl',\n",
    "    'text_idf.pkl'\n",
    "]\n",
    "\n",
    "if IS_COLAB or os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'):\n",
    "    try:\n",
    "        bucket_name = 'yali-ir2025-bucket'\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        \n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "\n",
    "        for filename in FILES_TO_DOWNLOAD:\n",
    "            blob = bucket.blob(filename)\n",
    "            if blob.exists():\n",
    "                print(f\"Downloading {filename}...\")\n",
    "                blob.download_to_filename(filename)\n",
    "                # Also copy to data/ just in case\n",
    "                import shutil\n",
    "                shutil.copy(filename, f'data/{filename}')\n",
    "            else:\n",
    "                print(f\"{filename} not found in bucket. Skipping.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading files: {e}\")\n",
    "else:\n",
    "    print(\"No credentials. Skipping file downloads.\")\n",
    "\n",
    "# Ensure we have at least dummy data for doc_lengths to prevent ZeroDivisionError\n",
    "import pickle\n",
    "if not os.path.exists('doc_lengths.pkl') and not os.path.exists('data/doc_lengths.pkl'):\n",
    "    print(\"Creating dummy doc_lengths.pkl to prevent ZeroDivisionError...\")\n",
    "    dummy_dl = {1: 1} # At least one document\n",
    "    with open('doc_lengths.pkl', 'wb') as f:\n",
    "        pickle.dump(dummy_dl, f)\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    import shutil\n",
    "    shutil.copy('doc_lengths.pkl', 'data/doc_lengths.pkl')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\סמסטר א\\אחזור מידע\\פרויקט\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.11) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_to_title.pkl not found in bucket. Skipping.\n",
      "page_rank.pkl not found in bucket. Skipping.\n",
      "page_views.pkl not found in bucket. Skipping.\n",
      "doc_lengths.pkl not found in bucket. Skipping.\n",
      "doc_norm_text.pkl not found in bucket. Skipping.\n",
      "text_idf.pkl not found in bucket. Skipping.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dW0y91OVu5J"
   },
   "source": [
    "# Run the app"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7opNkV6uRHIv",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:06:00.824612600Z",
     "start_time": "2026-01-03T20:05:55.884003300Z"
    }
   },
   "source": [
    "# Import the frontend module\n",
    "# Ensure you have 'src' in your python path (see cell above)\n",
    "try:\n",
    "    import search_frontend as se\n",
    "except ImportError:\n",
    "    # Fallback if running from a different directory context\n",
    "    from src import search_frontend as se\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading inverted indexes...\n",
      "Could not load local body index: [Errno 2] No such file or directory: 'data\\\\postings_gcp\\\\index.pkl'\n",
      "Loaded body index from bucket.\n",
      "Could not load title index.\n",
      "Could not load anchor index.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oTGXXYEXV5l8",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:06:02.244357500Z",
     "start_time": "2026-01-03T20:06:02.219439500Z"
    }
   },
   "source": [
    "# uncomment the code below and execute to reload the module when you make\n",
    "# changes to search_frontend.py (after you upload again).\n",
    "# import importlib\n",
    "# importlib.reload(se)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "k7K7oFlfVhm5",
    "outputId": "8f31e64f-e631-4dca-a182-ea283cf9ecf0",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:06:06.709059Z",
     "start_time": "2026-01-03T20:06:03.635038600Z"
    }
   },
   "source": [
    "import threading\n",
    "import time\n",
    "import requests\n",
    "\n",
    "PORT = 8080\n",
    "\n",
    "def run_server():\n",
    "    # Run the app\n",
    "    # Note: use_reloader=False is important in notebooks/background threads\n",
    "    try:\n",
    "        se.app.run(host='0.0.0.0', port=PORT, debug=False, use_reloader=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Server failed to start: {e}\")\n",
    "\n",
    "# Start the server in a background thread\n",
    "print(f\"Starting server on port {PORT}...\")\n",
    "server_thread = threading.Thread(target=run_server)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(3) \n",
    "\n",
    "# Check if server is up\n",
    "if IS_COLAB:\n",
    "    from google.colab.output import eval_js\n",
    "    server_url = eval_js(f\"google.colab.kernel.proxyPort({PORT})\")\n",
    "    print(f\"Colab Server URL: {server_url}\")\n",
    "else:\n",
    "    server_url = f\"http://127.0.0.1:{PORT}\"\n",
    "    print(f\"Local Server URL: {server_url}\")\n",
    "\n",
    "try:\n",
    "    # Simple health check\n",
    "    requests.get(server_url)\n",
    "    print(\"Server is up and running!\")\n",
    "except:\n",
    "    print(\"Warning: Server might not be reachable yet or failed to start.\")\n",
    "\n",
    "print(f\"Test URL: {server_url}/search_body?query=hello+world\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server on port 8080...\n",
      " * Serving Flask app 'search_frontend'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.7.14:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [03/Jan/2026 22:06:06] \"GET / HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Server URL: http://127.0.0.1:8080\n",
      "Server is up and running!\n",
      "Test URL: http://127.0.0.1:8080/search_body?query=hello+world\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na0MC_1nzDbi"
   },
   "source": [
    "# Testing your app\n",
    "\n",
    "Once your app is running you can query it. You can simply do that by clicking on the URL printed above (the one looking like https://XXXXX-5000-colab.googleusercontent.com/search?query=hello+world or by issuing an HTTP request through code (from colab).\n",
    "\n",
    "The code below shows how to issue a query from python. This is also how our testing code will issue queries to your search engine, so make sure to test your search engine this way after you deploy it to GCP and before submission. Command line instructions for deploying your search engine to GCP are available at `run_frontend_in_gcp.sh`. Note that we will not only issue training queries to your search engine, but also test queries, i.e. queries that you've never seen before."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EM5ePrRHojbG",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:06:10.379113100Z",
     "start_time": "2026-01-03T20:06:10.340982400Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Path to queries file\n",
    "# Try 'data/queries_train.json' (relative to project root) or just 'queries_train.json'\n",
    "queries_path = os.path.join(project_root, 'data', 'queries_train.json')\n",
    "if not os.path.exists(queries_path):\n",
    "    queries_path = 'queries_train.json' # Fallback\n",
    "\n",
    "print(f\"Loading queries from: {queries_path}\")\n",
    "with open(queries_path, 'rt') as f:\n",
    "  queries = json.load(f)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading queries from: C:\\Users\\User\\Desktop\\סמסטר א\\אחזור מידע\\פרויקט\\data\\queries_train.json\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gWimZWCOy3Ei",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:06:12.835768100Z",
     "start_time": "2026-01-03T20:06:12.812222200Z"
    }
   },
   "source": [
    "def average_precision(true_list, predicted_list, k=40):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    precisions = []\n",
    "    for i,doc_id in enumerate(predicted_list):\n",
    "        if doc_id in true_set:\n",
    "            prec = (len(precisions)+1) / (i+1)\n",
    "            precisions.append(prec)\n",
    "    if len(precisions) == 0:\n",
    "        return 0.0\n",
    "    return round(sum(precisions)/len(precisions),3)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "geHKyFB4xkBe",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:06:14.172287400Z",
     "start_time": "2026-01-03T20:06:14.147937800Z"
    }
   },
   "source": [
    "def precision_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(predicted_list) == 0:\n",
    "        return 0.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(predicted_list), 3)\n",
    "def recall_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(true_set) < 1:\n",
    "        return 1.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(true_set), 3)\n",
    "def f1_at_k(true_list, predicted_list, k):\n",
    "    p = precision_at_k(true_list, predicted_list, k)\n",
    "    r = recall_at_k(true_list, predicted_list, k)\n",
    "    if p == 0.0 or r == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p + 1.0/r), 3)\n",
    "def results_quality(true_list, predicted_list):\n",
    "    p5 = precision_at_k(true_list, predicted_list, 5)\n",
    "    f1_30 = f1_at_k(true_list, predicted_list, 30)\n",
    "    if p5 == 0.0 or f1_30 == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p5 + 1.0/f1_30), 3)\n",
    "\n",
    "assert precision_at_k(range(10), [1,2,3] , 2) == 1.0\n",
    "assert recall_at_k(   range(10), [10,5,3], 2) == 0.1\n",
    "assert precision_at_k(range(10), []      , 2) == 0.0\n",
    "assert precision_at_k([],        [1,2,3],  5) == 0.0\n",
    "assert recall_at_k(   [],        [10,5,3], 2) == 1.0\n",
    "assert recall_at_k(   range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       [],        [1,2,3],  5) == 0.0\n",
    "assert f1_at_k(       range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       range(10), [0,1,2],  2) == 0.333\n",
    "assert f1_at_k(       range(50), range(5), 30) == 0.182\n",
    "assert f1_at_k(       range(50), range(10), 30) == 0.333\n",
    "assert f1_at_k(       range(50), range(30), 30) == 0.75\n",
    "assert results_quality(range(50), range(5))  == 0.308\n",
    "assert results_quality(range(50), range(10)) == 0.5\n",
    "assert results_quality(range(50), range(30)) == 0.857\n",
    "assert results_quality(range(50), [-1]*5 + list(range(5,30))) == 0.0\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dYmNTq9u0ChK",
    "ExecuteTime": {
     "end_time": "2026-01-03T20:10:52.196737900Z",
     "start_time": "2026-01-03T20:06:17.090602700Z"
    }
   },
   "source": [
    "import requests\n",
    "from time import time\n",
    "\n",
    "# Use the server_url defined in the previous cell\n",
    "# If it's not defined, fallback to localhost\n",
    "if 'server_url' not in locals():\n",
    "    server_url = 'http://127.0.0.1:8080'\n",
    "\n",
    "print(f\"Testing against: {server_url}\")\n",
    "\n",
    "qs_res = []\n",
    "for q, true_wids in queries.items():\n",
    "  duration, ap = None, None\n",
    "  t_start = time()\n",
    "  try:\n",
    "    # Note: Using /search_body for now as that's what we implemented\n",
    "    # The original code used /search. You can change this back later.\n",
    "    res = requests.get(server_url + '/search_body', {'query': q}, timeout=35)\n",
    "    duration = time() - t_start\n",
    "    if res.status_code == 200:\n",
    "      # The response is a list of (doc_id, title)\n",
    "      # We need just the doc_ids for evaluation\n",
    "      results = res.json()\n",
    "      pred_wids = [str(doc_id) for doc_id, title in results]\n",
    "      \n",
    "      # Calculate quality metrics\n",
    "      rq = results_quality(true_wids, pred_wids)\n",
    "      ap = average_precision(true_wids, pred_wids)\n",
    "      \n",
    "      print(f\"Query: {q} | Duration: {duration:.3f}s | Quality: {rq} | AP: {ap}\")\n",
    "    else:\n",
    "        print(f\"Query: {q} | Failed with status {res.status_code}\")\n",
    "  except Exception as e:\n",
    "    print(f\"Query: {q} | Error: {e}\")\n",
    "\n",
    "  qs_res.append((q, duration, ap))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing against: http://127.0.0.1:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:06:28] \"GET /search_body?query=Mount+Everest+climbing+expeditions HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Mount Everest climbing expeditions | Duration: 11.237s | Quality: 0.198 | AP: 0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:06:42] \"GET /search_body?query=Great+Fire+of+London+1666 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Great Fire of London 1666 | Duration: 14.317s | Quality: 0.0 | AP: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:06:49] \"GET /search_body?query=Nanotechnology+materials+science HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Nanotechnology materials science | Duration: 6.780s | Quality: 0.571 | AP: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:06:57] \"GET /search_body?query=Fossil+fuels+climate+change HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Fossil fuels climate change | Duration: 8.505s | Quality: 0.291 | AP: 0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:07:07] \"GET /search_body?query=DNA+double+helix+discovery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: DNA double helix discovery | Duration: 9.106s | Quality: 0.311 | AP: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:07:15] \"GET /search_body?query=Printing+press+invention+Gutenberg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Printing press invention Gutenberg | Duration: 8.880s | Quality: 0.425 | AP: 0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:07:25] \"GET /search_body?query=Ancient+Egypt+pyramids+pharaohs HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Ancient Egypt pyramids pharaohs | Duration: 9.549s | Quality: 0.377 | AP: 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:07:34] \"GET /search_body?query=Gothic+literature+Mary+Shelley HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Gothic literature Mary Shelley | Duration: 9.083s | Quality: 0.236 | AP: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:07:42] \"GET /search_body?query=Robotics+automation+industry HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Robotics automation industry | Duration: 7.689s | Quality: 0.283 | AP: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:07:53] \"GET /search_body?query=Television+invention+broadcast+media HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Television invention broadcast media | Duration: 11.483s | Quality: 0.0 | AP: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:02] \"GET /search_body?query=Wright+brothers+first+flight HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Wright brothers first flight | Duration: 8.423s | Quality: 0.0 | AP: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:07] \"GET /search_body?query=Steam+locomotive+transportation+history HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Steam locomotive transportation history | Duration: 5.360s | Quality: 0.175 | AP: 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:13] \"GET /search_body?query=Currency+history+gold+standard HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Currency history gold standard | Duration: 5.809s | Quality: 0.201 | AP: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:23] \"GET /search_body?query=Renaissance+art+Leonardo+da+Vinci HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Renaissance art Leonardo da Vinci | Duration: 9.733s | Quality: 0.457 | AP: 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:32] \"GET /search_body?query=Shakespeare+plays+Elizabethan+theatre HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Shakespeare plays Elizabethan theatre | Duration: 9.658s | Quality: 0.188 | AP: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:40] \"GET /search_body?query=Solar+eclipse+astronomy+observation HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Solar eclipse astronomy observation | Duration: 7.812s | Quality: 0.198 | AP: 0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:48] \"GET /search_body?query=Renaissance+architecture+Florence+Italy HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Renaissance architecture Florence Italy | Duration: 8.419s | Quality: 0.25 | AP: 0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:08:55] \"GET /search_body?query=Impressionism+Monet+Renoir HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Impressionism Monet Renoir | Duration: 6.332s | Quality: 0.364 | AP: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:09:04] \"GET /search_body?query=Samurai+code+Bushido+Japan HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Samurai code Bushido Japan | Duration: 9.050s | Quality: 0.231 | AP: 0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:09:16] \"GET /search_body?query=Fossil+record+paleontology+evidence HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Fossil record paleontology evidence | Duration: 11.848s | Quality: 0.165 | AP: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:09:27] \"GET /search_body?query=Silk+Road+trade+cultural+exchange HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Silk Road trade cultural exchange | Duration: 11.814s | Quality: 0.165 | AP: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:09:35] \"GET /search_body?query=Industrial+Revolution+steam+engines HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Industrial Revolution steam engines | Duration: 7.655s | Quality: 0.417 | AP: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:09:45] \"GET /search_body?query=Green+Revolution+agriculture+yield HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Green Revolution agriculture yield | Duration: 10.096s | Quality: 0.0 | AP: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:09:56] \"GET /search_body?query=Quantum+computing+future+technology HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Quantum computing future technology | Duration: 11.138s | Quality: 0.368 | AP: 0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:10:12] \"GET /search_body?query=Viking+exploration+North+America HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Viking exploration North America | Duration: 15.476s | Quality: 0.229 | AP: 0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:10:21] \"GET /search_body?query=Roman+aqueducts+engineering+innovation HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Roman aqueducts engineering innovation | Duration: 9.122s | Quality: 0.202 | AP: 0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:10:27] \"GET /search_body?query=Coffee+history+Ethiopia+trade HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Coffee history Ethiopia trade | Duration: 5.983s | Quality: 0.447 | AP: 0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:10:32] \"GET /search_body?query=Stonehenge+prehistoric+monument HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Stonehenge prehistoric monument | Duration: 5.303s | Quality: 0.397 | AP: 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:10:38] \"GET /search_body?query=Photography+invention+Daguerre HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Photography invention Daguerre | Duration: 6.040s | Quality: 0.381 | AP: 0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jan/2026 22:10:52] \"GET /search_body?query=Ballet+origins+France+Russia HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Ballet origins France Russia | Duration: 13.371s | Quality: 0.193 | AP: 0.255\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
